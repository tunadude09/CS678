{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import Tensor\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread, imresize, imsave, imshow\n",
    "from imagenet_classes import class_names \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  load fine grained classifcation dataset from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_1 = json.load(open(\"/home/tuna/Projects/CS601R/Project3/lab10/lib/cub_metadata.json\", \"r\"))\n",
    "meta_2 = pickle.load(open(\"/home/tuna/Projects/CS601R/Project3/lab10/lib/cub_metadata.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  remove number prefixes from names\n",
    "for inst in meta_2['class_names']:\n",
    "    meta_2['class_names'][inst] = meta_2['class_names'][inst][4:].lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'black_footed_albatross'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_2['class_names'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  clean up imageNet classes for comparison\n",
    "standardized_class_names = []\n",
    "for name in class_names:\n",
    "    standardized_class_names.append(\"_\".join(re.split(\"[^a-zA-Z\\d:]+\", name.lower())))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootdir = '/home/tuna/Projects/CS601R/Project3/lab10/lib/images_sq224'\n",
    "\n",
    "all_ims_original = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        all_ims_original.append( imresize(imread(os.path.join(subdir, file), mode='RGB'), (224, 224)))\n",
    "    \n",
    "all_ims_original = np.asarray(all_ims_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  create training/test sets\n",
    "\n",
    "test_data_original = []\n",
    "test_classes_original = []\n",
    "\n",
    "# for i in range(1, len(meta_2['train_test_split']['testing'])):\n",
    "for i in range(1, 5):\n",
    "    test_data_original.extend(all_ims_original[meta_2['train_test_split']['testing'][i]])\n",
    "    test_classes_original.extend([i] * len(meta_2['train_test_split']['testing'][i])) \n",
    "    \n",
    "    \n",
    "    \n",
    "train_data_original = []\n",
    "train_classes_original = []\n",
    "\n",
    "# for i in range(1, len(meta_2['train_test_split']['training'])):\n",
    "for i in range(1, 5):\n",
    "    train_data_original.extend(all_ims_original[meta_2['train_test_split']['training'][i]])\n",
    "    train_classes_original.extend([i] * len(meta_2['train_test_split']['training'][i]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  get class names\n",
    "def get_class_names(passed_indexes):\n",
    "    class_names = []\n",
    "    for i in passed_indexes:\n",
    "        class_names.append(meta_2['class_names'][i])\n",
    "    \n",
    "    return class_names\n",
    "\n",
    "test_classes_original_names = get_class_names(test_classes_original)\n",
    "train_classes_original_names = get_class_names(train_classes_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  one hot encoded versions\n",
    "\n",
    "train_classes_ohe = np.zeros((len(train_classes_original),5))\n",
    "for i,c in enumerate(train_classes_original):\n",
    "    train_classes_ohe[i,c] = 1.0\n",
    "    \n",
    "test_classes_ohe = np.zeros((len(test_classes_original),5))\n",
    "for i,c in enumerate(test_classes_original):\n",
    "    test_classes_ohe[i,c] = 1.0\n",
    "    \n",
    "    \n",
    "train_classes_ohe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "\"\"\"Define get next batch method\"\"\"\n",
    "def get_next_batch(data, classes, num_to_select):\n",
    "  #  shuffle with labels\n",
    "  data_shuffled_mat =  np.asarray(zip(data, classes))\n",
    "  np.random.shuffle(data_shuffled_mat)\n",
    "  \n",
    "  data_mat_selected = np.asarray(list(data_shuffled_mat[:num_to_select,0]))\n",
    "  data_classes_selected = np.asarray(list(data_shuffled_mat[:num_to_select,1]))\n",
    "  \n",
    "  return data_mat_selected.astype(float), data_classes_selected.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_test_batch_data,tmp_test_batch_labels  = get_next_batch(train_data_original, train_classes_ohe, 2)\n",
    "tmp_test_batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCNN with BIRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20)\n",
      "it begins\n",
      "(?, 20)\n",
      "(?, 20)\n",
      "(?, 20, 1)\n",
      "(?, 1, 20)\n",
      "(?, 20, 20)\n",
      "It ends\n",
      "(?, 20, 20)\n",
      "(?, ?)\n",
      "(?, 5)\n",
      "step 0, training accuracy 0.24\n",
      "step 1, training accuracy 0.24\n",
      "step 2, training accuracy 0.18\n",
      "step 3, training accuracy 0.26\n",
      "step 4, training accuracy 0.24\n",
      "step 5, training accuracy 0.22\n",
      "step 6, training accuracy 0.32\n",
      "step 7, training accuracy 0.34\n",
      "step 8, training accuracy 0.18\n",
      "step 9, training accuracy 0.22\n",
      "step 10, training accuracy 0.26\n",
      "step 11, training accuracy 0.24\n",
      "step 12, training accuracy 0.3\n",
      "step 13, training accuracy 0.26\n",
      "step 14, training accuracy 0.3\n",
      "step 15, training accuracy 0.2\n",
      "step 16, training accuracy 0.26\n",
      "step 17, training accuracy 0.26\n",
      "step 18, training accuracy 0.32\n",
      "step 19, training accuracy 0.28\n",
      "step 20, training accuracy 0.24\n",
      "step 21, training accuracy 0.24\n",
      "step 22, training accuracy 0.34\n",
      "step 23, training accuracy 0.24\n",
      "step 24, training accuracy 0.22\n",
      "step 25, training accuracy 0.24\n",
      "step 26, training accuracy 0.32\n",
      "step 27, training accuracy 0.14\n",
      "step 28, training accuracy 0.28\n",
      "step 29, training accuracy 0.22\n",
      "step 30, training accuracy 0.32\n",
      "step 31, training accuracy 0.28\n",
      "step 32, training accuracy 0.26\n",
      "step 33, training accuracy 0.24\n",
      "step 34, training accuracy 0.28\n",
      "step 35, training accuracy 0.14\n",
      "step 36, training accuracy 0.26\n",
      "step 37, training accuracy 0.28\n",
      "step 38, training accuracy 0.22\n",
      "step 39, training accuracy 0.26\n",
      "step 40, training accuracy 0.24\n",
      "step 41, training accuracy 0.3\n",
      "step 42, training accuracy 0.26\n",
      "step 43, training accuracy 0.3\n",
      "step 44, training accuracy 0.34\n",
      "step 45, training accuracy 0.24\n",
      "step 46, training accuracy 0.34\n",
      "step 47, training accuracy 0.26\n",
      "step 48, training accuracy 0.28\n",
      "step 49, training accuracy 0.28\n",
      "step 50, training accuracy 0.22\n",
      "step 51, training accuracy 0.24\n",
      "step 52, training accuracy 0.3\n",
      "step 53, training accuracy 0.28\n",
      "step 54, training accuracy 0.24\n",
      "step 55, training accuracy 0.22\n",
      "step 56, training accuracy 0.28\n",
      "step 57, training accuracy 0.26\n",
      "step 58, training accuracy 0.32\n",
      "step 59, training accuracy 0.26\n",
      "step 60, training accuracy 0.2\n",
      "step 61, training accuracy 0.3\n",
      "step 62, training accuracy 0.24\n",
      "step 63, training accuracy 0.26\n",
      "step 64, training accuracy 0.16\n",
      "step 65, training accuracy 0.32\n",
      "step 66, training accuracy 0.14\n",
      "step 67, training accuracy 0.24\n",
      "step 68, training accuracy 0.22\n",
      "step 69, training accuracy 0.32\n",
      "step 70, training accuracy 0.22\n",
      "step 71, training accuracy 0.22\n",
      "step 72, training accuracy 0.28\n",
      "step 73, training accuracy 0.28\n",
      "step 74, training accuracy 0.26\n",
      "step 75, training accuracy 0.2\n",
      "step 76, training accuracy 0.18\n",
      "step 77, training accuracy 0.26\n",
      "step 78, training accuracy 0.32\n",
      "step 79, training accuracy 0.22\n",
      "step 80, training accuracy 0.22\n",
      "step 81, training accuracy 0.34\n",
      "step 82, training accuracy 0.32\n",
      "step 83, training accuracy 0.26\n",
      "step 84, training accuracy 0.3\n",
      "step 85, training accuracy 0.22\n",
      "step 86, training accuracy 0.18\n",
      "step 87, training accuracy 0.22\n",
      "step 88, training accuracy 0.26\n",
      "step 89, training accuracy 0.3\n",
      "step 90, training accuracy 0.32\n",
      "step 91, training accuracy 0.24\n",
      "step 92, training accuracy 0.28\n",
      "step 93, training accuracy 0.32\n",
      "step 94, training accuracy 0.3\n",
      "step 95, training accuracy 0.26\n",
      "step 96, training accuracy 0.24\n",
      "step 97, training accuracy 0.22\n",
      "step 98, training accuracy 0.36\n",
      "step 99, training accuracy 0.28\n",
      "test accuracy 0.254237\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()    \n",
    "   \n",
    "batch_size = 50\n",
    "    \n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def max_pool_4x4(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 4, 4, 1],\n",
    "                        strides=[1, 4, 4, 1], padding='SAME')\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')    \n",
    "    \n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=1e-4)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('Wx_B') as scope:\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 224, 224, 3])\n",
    "    x_batch_size = tf.shape(x)[0]\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "    x_image = tf.reshape(x, [-1,224, 224, 3])\n",
    "\n",
    "    \n",
    "    with tf.name_scope('bilinear_model_1') as scope:\n",
    "        W_conv1_bnn1 = weight_variable([5, 5, 3, 32])\n",
    "        b_conv1_bnn1 = bias_variable([32])\n",
    "        h_conv1_bnn1 = tf.nn.relu(conv2d(x_image, W_conv1_bnn1) + b_conv1_bnn1)\n",
    "        h_pool1_bnn1 = max_pool_2x2(h_conv1_bnn1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_conv2_bnn1 = weight_variable([5, 5, 32, 40])\n",
    "        b_conv2_bnn1 = bias_variable([40])\n",
    "        h_conv2_bnn1 = tf.nn.relu(conv2d(h_pool1_bnn1, W_conv2_bnn1) + b_conv2_bnn1)\n",
    "        h_pool2_bnn1 = max_pool_2x2(h_conv2_bnn1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_conv3_bnn1 = weight_variable([5, 5, 40, 16])\n",
    "        b_conv3_bnn1 = bias_variable([16])\n",
    "        h_conv3_bnn1 = tf.nn.relu(conv2d(h_pool2_bnn1, W_conv3_bnn1) + b_conv3_bnn1)\n",
    "    #     h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_fc1_bnn1 = weight_variable([56 * 56 * 16, 20])\n",
    "        b_fc1_bnn1 = bias_variable([20])\n",
    "        h_conv3_flat_bnn1 = tf.reshape(h_conv3_bnn1, [-1, 56 * 56 * 16])\n",
    "        h_fc1_bnn1 = tf.nn.relu(tf.matmul(h_conv3_flat_bnn1, W_fc1_bnn1) + b_fc1_bnn1)\n",
    "\n",
    "\n",
    "\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        y_raw_bnn1 = h_fc1_bnn1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    with tf.name_scope('bilinear_model_2') as scope:\n",
    "        W_conv1_bnn2 = weight_variable([5, 5, 3, 32])\n",
    "        b_conv1_bnn2 = bias_variable([32])\n",
    "        h_conv1_bnn2 = tf.nn.relu(conv2d(x_image, W_conv1_bnn2) + b_conv1_bnn2)\n",
    "        h_pool1_bnn2 = max_pool_2x2(h_conv1_bnn2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_conv2_bnn2 = weight_variable([5, 5, 32, 42])\n",
    "        b_conv2_bnn2 = bias_variable([42])\n",
    "        h_conv2_bnn2 = tf.nn.relu(conv2d(h_pool1_bnn2, W_conv2_bnn2) + b_conv2_bnn2)\n",
    "        h_pool2_bnn2 = max_pool_2x2(h_conv2_bnn2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_conv3_bnn2 = weight_variable([5, 5, 42, 16])\n",
    "        b_conv3_bnn2 = bias_variable([16])\n",
    "        h_conv3_bnn2 = tf.nn.relu(conv2d(h_pool2_bnn2, W_conv3_bnn2) + b_conv3_bnn2)\n",
    "    #     h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_fc1_bnn2 = weight_variable([56 * 56 * 16, 20])\n",
    "        b_fc1_bnn2 = bias_variable([20])\n",
    "        h_conv3_flat_bnn2 = tf.reshape(h_conv3_bnn2, [-1, 56 * 56 * 16])\n",
    "        h_fc1_bnn2 = tf.nn.relu(tf.matmul(h_conv3_flat_bnn2, W_fc1_bnn2) + b_fc1_bnn2)\n",
    "\n",
    "\n",
    "\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        y_raw_bnn2 = h_fc1_bnn2\n",
    "\n",
    "\n",
    "\n",
    "    with tf.name_scope('outer_product') as scope:\n",
    "\n",
    "\n",
    "        def batch_outer_product(x, y):\n",
    "            print(\"it begins\")\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "\n",
    "    #         x_transposed = tf.transpose(x)\n",
    "            x_transposed = x\n",
    "    #         print x_transposed.get_shape()  # ==> [N, U]\n",
    "\n",
    "            x_transposed_as_matrix_batch = tf.expand_dims(x_transposed, 2)\n",
    "            print(x_transposed_as_matrix_batch.shape)\n",
    "    #         print x_transposed_as_matrix_batch.get_shape()  # ==> [N, U, 1]\n",
    "\n",
    "            y_as_matrix_batch = tf.expand_dims(y, 1)\n",
    "            print(y_as_matrix_batch.shape)\n",
    "\n",
    "    #         print y_as_matrix_batch.get_shape()  # ==> [N, 1, V]\n",
    "\n",
    "            result = tf.matmul(x_transposed_as_matrix_batch, y_as_matrix_batch)\n",
    "\n",
    "            print(result.shape)\n",
    "    #         result = tf.batch_matmul(x_transposed_as_matrix_batch, y_as_matrix_batch)\n",
    "        #         print result.get_shape()  # ==> [N, U, V]\n",
    "            print(\"It ends\")\n",
    "            return result\n",
    "\n",
    "\n",
    "\n",
    "        #  shape 50 x 10, to 50 x 100\n",
    "        print(y_raw_bnn1.shape)\n",
    "        y_outer_product = batch_outer_product(y_raw_bnn1, y_raw_bnn2)\n",
    "        print(y_outer_product.shape)\n",
    "\n",
    "\n",
    "    #     #  shape = 50 x 100\n",
    "        y_outer_product_vec = tf.nn.relu(tf.sqrt(tf.reshape(y_outer_product, [x_batch_size,-1])))\n",
    "        print(y_outer_product_vec.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #  final fc layer transformation to 10 classes\n",
    "    W_fc3 = weight_variable([400, 5])\n",
    "    b_fc3 = bias_variable([5])\n",
    "    y_fc3 = tf.matmul(y_outer_product_vec, W_fc3) + b_fc3\n",
    "\n",
    "    \n",
    "    y_conv=tf.nn.softmax(y_fc3)\n",
    "    out_shape = tf.shape(y_conv)\n",
    "    print(y_conv.shape)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#  FINE AFTER HERE\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def l2_loss(tensor_inst):\n",
    "    return tf.reduce_sum(tensor_inst ** 2)\n",
    "beta = 0.0001\n",
    "\n",
    "with tf.name_scope('cost') as scope:\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1])) + \\\n",
    "                beta*l2_loss(W_conv1_bnn1) +\\\n",
    "                beta*l2_loss(b_conv1_bnn1) +\\\n",
    "                beta*l2_loss(W_conv2_bnn1) +\\\n",
    "                beta*l2_loss(b_conv2_bnn1) +\\\n",
    "                beta*l2_loss(W_conv3_bnn1) +\\\n",
    "                beta*l2_loss(b_conv3_bnn1) +\\\n",
    "                beta*l2_loss(W_fc1_bnn1) +\\\n",
    "                beta*l2_loss(b_fc1_bnn1) +\\\n",
    "                beta*l2_loss(W_conv1_bnn2) +\\\n",
    "                beta*l2_loss(b_conv1_bnn2) +\\\n",
    "                beta*l2_loss(W_conv2_bnn2) +\\\n",
    "                beta*l2_loss(b_conv2_bnn2) +\\\n",
    "                beta*l2_loss(W_conv3_bnn2) +\\\n",
    "                beta*l2_loss(b_conv3_bnn2) +\\\n",
    "                beta*l2_loss(W_fc1_bnn2) +\\\n",
    "                beta*l2_loss(b_fc1_bnn2) +\\\n",
    "                beta*l2_loss(W_fc3) +\\\n",
    "                beta*l2_loss(b_fc3)\n",
    "#                 beta*l2_loss(W_fc2) +\\\n",
    "#                 beta*l2_loss(b_fc2) +\\\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('optimizer') as scope:\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('accuracy') as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  summary writers for debugging\n",
    "summary_writer = tf.summary.FileWriter( '/home/tuna/Projects/CS678/Deep_Learning_Project_2/tf_logs/full_bilinear_test_birds_1', graph=sess.graph )\n",
    "acc_summary = tf.summary.scalar( 'accuracy', accuracy )\n",
    "loss_summary = tf.summary.scalar( 'loss', cross_entropy )\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "#   batch = mnist.train.next_batch(batch_size)\n",
    "  batch_xs, batch_ys = get_next_batch(train_data_original, train_classes_ohe, batch_size)\n",
    "\n",
    "    \n",
    "    \n",
    "#   print(\"Batch\", i)\n",
    "  if i%1 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "#   summary, _, outshape, wc111, bc111, yop, yr, yopv, yc, hp1, hp2 = sess.run([merged_summary_op,train_step,out_shape, W_conv1, b_conv1, y_outer_product, y_raw, y_outer_product_vec, y_conv, h_pool1, h_pool2], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "  summary, _, outshape, wc111, bc111, yc, hp1 = sess.run([merged_summary_op,train_step,out_shape, W_conv1_bnn1, b_conv1_bnn1,  y_conv, h_pool1_bnn1], feed_dict={x:batch_xs, y_: batch_ys, keep_prob: 0.5})\n",
    "  summary_writer.add_summary(summary, i)\n",
    "#   print(\"out shape\", outshape)\n",
    "#   print(\"wc1\", wc111)\n",
    "#   print(\"bc1\", bc111)\n",
    "#   print(\"hp1\", hp1)\n",
    "#   print(\"hp2\", hp2)\n",
    "#   print(\"yr\", yr)\n",
    "#   print(\"yop\", yop)\n",
    "#   print(\"yopv\", yopv)\n",
    "#   print(\"yc\", yc)\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x:test_data_original, y_: test_classes_ohe, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "summary_writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20)\n",
      "it begins\n",
      "(?, 20)\n",
      "(?, 20)\n",
      "(?, 20, 1)\n",
      "(?, 1, 20)\n",
      "(?, 20, 20)\n",
      "It ends\n",
      "(?, 20, 20)\n",
      "(?, ?)\n",
      "(?, 10)\n",
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.12\n",
      "step 200, training accuracy 0.16\n",
      "step 300, training accuracy 0.14\n",
      "step 400, training accuracy 0.12\n",
      "step 500, training accuracy 0.1\n",
      "step 600, training accuracy 0.12\n",
      "step 700, training accuracy 0.12\n",
      "step 800, training accuracy 0.12\n",
      "step 900, training accuracy 0.06\n",
      "step 1000, training accuracy 0.12\n",
      "step 1100, training accuracy 0.12\n",
      "step 1200, training accuracy 0.14\n",
      "step 1300, training accuracy 0.16\n",
      "step 1400, training accuracy 0.14\n",
      "step 1500, training accuracy 0.1\n",
      "step 1600, training accuracy 0.08\n",
      "step 1700, training accuracy 0.16\n",
      "step 1800, training accuracy 0.08\n",
      "step 1900, training accuracy 0.12\n",
      "step 2000, training accuracy 0.06\n",
      "step 2100, training accuracy 0.12\n",
      "step 2200, training accuracy 0.06\n",
      "step 2300, training accuracy 0.12\n",
      "step 2400, training accuracy 0.04\n",
      "step 2500, training accuracy 0.14\n",
      "step 2600, training accuracy 0.12\n",
      "step 2700, training accuracy 0.08\n",
      "step 2800, training accuracy 0.1\n",
      "step 2900, training accuracy 0.08\n",
      "step 3000, training accuracy 0.16\n",
      "step 3100, training accuracy 0.06\n",
      "step 3200, training accuracy 0.1\n",
      "step 3300, training accuracy 0.1\n",
      "step 3400, training accuracy 0.1\n",
      "step 3500, training accuracy 0.04\n",
      "step 3600, training accuracy 0.08\n",
      "step 3700, training accuracy 0.06\n",
      "step 3800, training accuracy 0.12\n",
      "step 3900, training accuracy 0.08\n",
      "step 4000, training accuracy 0.12\n",
      "step 4100, training accuracy 0.1\n",
      "step 4200, training accuracy 0.22\n",
      "step 4300, training accuracy 0.06\n",
      "step 4400, training accuracy 0.1\n",
      "step 4500, training accuracy 0.04\n",
      "step 4600, training accuracy 0.1\n",
      "step 4700, training accuracy 0.12\n",
      "step 4800, training accuracy 0.1\n",
      "step 4900, training accuracy 0.06\n",
      "step 5000, training accuracy 0.1\n",
      "step 5100, training accuracy 0.08\n",
      "step 5200, training accuracy 0.12\n",
      "step 5300, training accuracy 0.12\n",
      "step 5400, training accuracy 0.14\n",
      "step 5500, training accuracy 0.18\n",
      "step 5600, training accuracy 0.14\n",
      "step 5700, training accuracy 0.16\n",
      "step 5800, training accuracy 0.12\n",
      "step 5900, training accuracy 0.14\n",
      "step 6000, training accuracy 0.18\n",
      "step 6100, training accuracy 0.04\n",
      "step 6200, training accuracy 0.08\n",
      "step 6300, training accuracy 0.12\n",
      "step 6400, training accuracy 0.1\n",
      "step 6500, training accuracy 0.06\n",
      "step 6600, training accuracy 0.08\n",
      "step 6700, training accuracy 0.04\n",
      "step 6800, training accuracy 0.2\n",
      "step 6900, training accuracy 0.14\n",
      "step 7000, training accuracy 0.12\n",
      "step 7100, training accuracy 0.12\n",
      "step 7200, training accuracy 0.12\n",
      "step 7300, training accuracy 0.1\n",
      "step 7400, training accuracy 0.14\n",
      "step 7500, training accuracy 0.1\n",
      "step 7600, training accuracy 0.1\n",
      "step 7700, training accuracy 0.04\n",
      "step 7800, training accuracy 0.12\n",
      "step 7900, training accuracy 0.22\n",
      "step 8000, training accuracy 0.08\n",
      "step 8100, training accuracy 0.14\n",
      "step 8200, training accuracy 0.1\n",
      "step 8300, training accuracy 0.16\n",
      "step 8400, training accuracy 0.06\n",
      "step 8500, training accuracy 0.14\n",
      "step 8600, training accuracy 0.08\n",
      "step 8700, training accuracy 0.18\n",
      "step 8800, training accuracy 0.14\n",
      "step 8900, training accuracy 0.08\n",
      "step 9000, training accuracy 0.12\n",
      "step 9100, training accuracy 0.08\n",
      "step 9200, training accuracy 0.1\n",
      "step 9300, training accuracy 0.18\n",
      "step 9400, training accuracy 0.14\n",
      "step 9500, training accuracy 0.16\n",
      "step 9600, training accuracy 0.06\n",
      "step 9700, training accuracy 0.1\n",
      "step 9800, training accuracy 0.14\n",
      "step 9900, training accuracy 0.04\n",
      "step 10000, training accuracy 0.14\n",
      "step 10100, training accuracy 0.08\n",
      "step 10200, training accuracy 0.02\n",
      "step 10300, training accuracy 0.06\n",
      "step 10400, training accuracy 0.1\n",
      "step 10500, training accuracy 0.08\n",
      "step 10600, training accuracy 0.1\n",
      "step 10700, training accuracy 0.04\n",
      "step 10800, training accuracy 0.08\n",
      "step 10900, training accuracy 0.14\n",
      "step 11000, training accuracy 0.22\n",
      "step 11100, training accuracy 0.08\n",
      "step 11200, training accuracy 0.14\n",
      "step 11300, training accuracy 0.12\n",
      "step 11400, training accuracy 0.16\n",
      "step 11500, training accuracy 0.18\n",
      "step 11600, training accuracy 0.06\n",
      "step 11700, training accuracy 0.12\n",
      "step 11800, training accuracy 0.1\n",
      "step 11900, training accuracy 0.08\n",
      "step 12000, training accuracy 0.06\n",
      "step 12100, training accuracy 0.2\n",
      "step 12200, training accuracy 0.08\n",
      "step 12300, training accuracy 0.1\n",
      "step 12400, training accuracy 0.1\n",
      "step 12500, training accuracy 0.1\n",
      "step 12600, training accuracy 0.1\n",
      "step 12700, training accuracy 0.18\n",
      "step 12800, training accuracy 0.12\n",
      "step 12900, training accuracy 0.1\n",
      "step 13000, training accuracy 0.08\n",
      "step 13100, training accuracy 0.08\n",
      "step 13200, training accuracy 0.12\n",
      "step 13300, training accuracy 0.1\n",
      "step 13400, training accuracy 0.02\n",
      "step 13500, training accuracy 0.1\n",
      "step 13600, training accuracy 0.12\n",
      "step 13700, training accuracy 0.1\n",
      "step 13800, training accuracy 0.14\n",
      "step 13900, training accuracy 0.02\n",
      "step 14000, training accuracy 0.06\n",
      "step 14100, training accuracy 0.08\n",
      "step 14200, training accuracy 0.1\n",
      "step 14300, training accuracy 0.04\n",
      "step 14400, training accuracy 0.06\n",
      "step 14500, training accuracy 0.1\n",
      "step 14600, training accuracy 0.16\n",
      "step 14700, training accuracy 0.08\n",
      "step 14800, training accuracy 0.12\n",
      "step 14900, training accuracy 0.12\n",
      "step 15000, training accuracy 0.12\n",
      "step 15100, training accuracy 0.18\n",
      "step 15200, training accuracy 0.1\n",
      "step 15300, training accuracy 0.06\n",
      "step 15400, training accuracy 0.08\n",
      "step 15500, training accuracy 0.02\n",
      "step 15600, training accuracy 0.1\n",
      "step 15700, training accuracy 0.12\n",
      "step 15800, training accuracy 0.12\n",
      "step 15900, training accuracy 0.02\n",
      "step 16000, training accuracy 0.12\n",
      "step 16100, training accuracy 0.3\n",
      "step 16200, training accuracy 0.16\n",
      "step 16300, training accuracy 0.2\n",
      "step 16400, training accuracy 0.16\n",
      "step 16500, training accuracy 0.1\n",
      "step 16600, training accuracy 0.1\n",
      "step 16700, training accuracy 0.18\n",
      "step 16800, training accuracy 0.12\n",
      "step 16900, training accuracy 0.1\n",
      "step 17000, training accuracy 0.16\n",
      "step 17100, training accuracy 0.1\n",
      "step 17200, training accuracy 0.1\n",
      "step 17300, training accuracy 0.12\n",
      "step 17400, training accuracy 0.18\n",
      "step 17500, training accuracy 0.08\n",
      "step 17600, training accuracy 0.22\n",
      "step 17700, training accuracy 0.04\n",
      "step 17800, training accuracy 0.16\n",
      "step 17900, training accuracy 0.08\n",
      "step 18000, training accuracy 0.18\n",
      "step 18100, training accuracy 0.12\n",
      "step 18200, training accuracy 0.14\n",
      "step 18300, training accuracy 0.2\n",
      "step 18400, training accuracy 0.14\n",
      "step 18500, training accuracy 0.12\n",
      "step 18600, training accuracy 0.08\n",
      "step 18700, training accuracy 0.08\n",
      "step 18800, training accuracy 0.1\n",
      "step 18900, training accuracy 0.12\n",
      "step 19000, training accuracy 0.1\n",
      "step 19100, training accuracy 0.14\n",
      "step 19200, training accuracy 0.18\n",
      "step 19300, training accuracy 0.04\n",
      "step 19400, training accuracy 0.12\n",
      "step 19500, training accuracy 0.14\n",
      "step 19600, training accuracy 0.18\n",
      "step 19700, training accuracy 0.06\n",
      "step 19800, training accuracy 0.16\n",
      "step 19900, training accuracy 0.12\n",
      "step 20000, training accuracy 0.14\n",
      "step 20100, training accuracy 0.06\n",
      "step 20200, training accuracy 0.1\n",
      "step 20300, training accuracy 0.12\n",
      "step 20400, training accuracy 0.12\n",
      "step 20500, training accuracy 0.12\n",
      "step 20600, training accuracy 0.06\n",
      "step 20700, training accuracy 0.04\n",
      "step 20800, training accuracy 0.06\n",
      "step 20900, training accuracy 0.08\n",
      "step 21000, training accuracy 0.1\n",
      "step 21100, training accuracy 0.16\n",
      "step 21200, training accuracy 0.18\n",
      "step 21300, training accuracy 0.02\n",
      "step 21400, training accuracy 0.08\n",
      "step 21500, training accuracy 0.16\n",
      "step 21600, training accuracy 0.12\n",
      "step 21700, training accuracy 0.1\n",
      "step 21800, training accuracy 0.18\n",
      "step 21900, training accuracy 0.08\n",
      "step 22000, training accuracy 0.1\n",
      "step 22100, training accuracy 0.22\n",
      "step 22200, training accuracy 0.1\n",
      "step 22300, training accuracy 0.1\n",
      "step 22400, training accuracy 0.08\n",
      "step 22500, training accuracy 0.2\n",
      "step 22600, training accuracy 0.08\n",
      "step 22700, training accuracy 0.04\n",
      "step 22800, training accuracy 0.14\n",
      "step 22900, training accuracy 0.06\n",
      "step 23000, training accuracy 0.14\n",
      "step 23100, training accuracy 0.18\n",
      "step 23200, training accuracy 0.08\n",
      "step 23300, training accuracy 0.14\n",
      "step 23400, training accuracy 0.08\n",
      "step 23500, training accuracy 0.14\n",
      "step 23600, training accuracy 0.1\n",
      "step 23700, training accuracy 0.04\n",
      "step 23800, training accuracy 0.06\n",
      "step 23900, training accuracy 0.12\n",
      "step 24000, training accuracy 0.12\n",
      "step 24100, training accuracy 0.08\n",
      "step 24200, training accuracy 0.1\n",
      "step 24300, training accuracy 0.18\n",
      "step 24400, training accuracy 0.22\n",
      "step 24500, training accuracy 0.08\n",
      "step 24600, training accuracy 0.06\n",
      "step 24700, training accuracy 0.12\n",
      "step 24800, training accuracy 0.12\n",
      "step 24900, training accuracy 0.14\n",
      "step 25000, training accuracy 0.14\n",
      "step 25100, training accuracy 0.14\n",
      "step 25200, training accuracy 0.06\n",
      "step 25300, training accuracy 0.06\n",
      "step 25400, training accuracy 0.12\n",
      "step 25500, training accuracy 0.08\n",
      "step 25600, training accuracy 0.04\n",
      "step 25700, training accuracy 0.14\n",
      "step 25800, training accuracy 0.08\n",
      "step 25900, training accuracy 0.2\n",
      "step 26000, training accuracy 0.14\n",
      "step 26100, training accuracy 0.1\n",
      "step 26200, training accuracy 0.06\n",
      "step 26300, training accuracy 0.08\n",
      "step 26400, training accuracy 0.08\n",
      "step 26500, training accuracy 0.12\n",
      "step 26600, training accuracy 0.12\n",
      "step 26700, training accuracy 0.22\n",
      "step 26800, training accuracy 0.18\n",
      "step 26900, training accuracy 0.08\n",
      "step 27000, training accuracy 0.12\n",
      "step 27100, training accuracy 0.06\n",
      "step 27200, training accuracy 0.1\n",
      "step 27300, training accuracy 0.14\n",
      "step 27400, training accuracy 0.16\n",
      "step 27500, training accuracy 0.16\n",
      "step 27600, training accuracy 0.14\n",
      "step 27700, training accuracy 0.1\n",
      "step 27800, training accuracy 0.04\n",
      "step 27900, training accuracy 0.06\n",
      "step 28000, training accuracy 0.04\n",
      "step 28100, training accuracy 0.06\n",
      "step 28200, training accuracy 0\n",
      "step 28300, training accuracy 0.14\n",
      "step 28400, training accuracy 0.14\n",
      "step 28500, training accuracy 0.08\n",
      "step 28600, training accuracy 0.06\n",
      "step 28700, training accuracy 0.16\n",
      "step 28800, training accuracy 0.06\n",
      "step 28900, training accuracy 0.1\n",
      "step 29000, training accuracy 0.12\n",
      "step 29100, training accuracy 0.14\n",
      "step 29200, training accuracy 0.14\n",
      "step 29300, training accuracy 0.18\n",
      "step 29400, training accuracy 0.14\n",
      "step 29500, training accuracy 0.14\n",
      "step 29600, training accuracy 0.12\n",
      "step 29700, training accuracy 0.06\n",
      "step 29800, training accuracy 0.08\n",
      "step 29900, training accuracy 0.16\n",
      "step 30000, training accuracy 0.06\n",
      "step 30100, training accuracy 0.14\n",
      "step 30200, training accuracy 0.02\n",
      "step 30300, training accuracy 0.1\n",
      "step 30400, training accuracy 0.06\n",
      "step 30500, training accuracy 0.06\n",
      "step 30600, training accuracy 0.12\n",
      "step 30700, training accuracy 0.08\n",
      "step 30800, training accuracy 0.06\n",
      "step 30900, training accuracy 0.12\n",
      "step 31000, training accuracy 0.1\n",
      "step 31100, training accuracy 0.08\n",
      "step 31200, training accuracy 0.1\n",
      "step 31300, training accuracy 0.16\n",
      "step 31400, training accuracy 0.06\n",
      "step 31500, training accuracy 0.16\n",
      "step 31600, training accuracy 0.12\n",
      "step 31700, training accuracy 0.08\n",
      "step 31800, training accuracy 0.16\n",
      "step 31900, training accuracy 0.1\n",
      "step 32000, training accuracy 0.22\n",
      "step 32100, training accuracy 0.12\n",
      "step 32200, training accuracy 0.04\n",
      "step 32300, training accuracy 0.24\n",
      "step 32400, training accuracy 0.14\n",
      "step 32500, training accuracy 0.22\n",
      "step 32600, training accuracy 0.22\n",
      "step 32700, training accuracy 0.16\n",
      "step 32800, training accuracy 0.1\n",
      "step 32900, training accuracy 0.04\n",
      "step 33000, training accuracy 0.08\n",
      "step 33100, training accuracy 0.14\n",
      "step 33200, training accuracy 0.1\n",
      "step 33300, training accuracy 0.16\n",
      "step 33400, training accuracy 0.06\n",
      "step 33500, training accuracy 0.12\n",
      "step 33600, training accuracy 0.08\n",
      "step 33700, training accuracy 0.16\n",
      "step 33800, training accuracy 0.1\n",
      "step 33900, training accuracy 0.08\n",
      "step 34000, training accuracy 0.08\n",
      "step 34100, training accuracy 0.12\n",
      "step 34200, training accuracy 0.06\n",
      "step 34300, training accuracy 0.06\n",
      "step 34400, training accuracy 0.16\n",
      "step 34500, training accuracy 0.1\n",
      "step 34600, training accuracy 0.1\n",
      "step 34700, training accuracy 0.06\n",
      "step 34800, training accuracy 0.06\n",
      "step 34900, training accuracy 0.08\n",
      "step 35000, training accuracy 0.1\n",
      "step 35100, training accuracy 0.14\n",
      "step 35200, training accuracy 0.1\n",
      "step 35300, training accuracy 0.14\n",
      "step 35400, training accuracy 0.16\n",
      "step 35500, training accuracy 0.1\n",
      "step 35600, training accuracy 0.1\n",
      "step 35700, training accuracy 0.14\n",
      "step 35800, training accuracy 0.2\n",
      "step 35900, training accuracy 0.12\n",
      "step 36000, training accuracy 0.08\n",
      "step 36100, training accuracy 0.12\n",
      "step 36200, training accuracy 0.1\n",
      "step 36300, training accuracy 0.04\n",
      "step 36400, training accuracy 0.06\n",
      "step 36500, training accuracy 0.16\n",
      "step 36600, training accuracy 0.12\n",
      "step 36700, training accuracy 0.12\n",
      "step 36800, training accuracy 0.16\n",
      "step 36900, training accuracy 0.16\n",
      "step 37000, training accuracy 0.06\n",
      "step 37100, training accuracy 0.16\n",
      "step 37200, training accuracy 0.12\n",
      "step 37300, training accuracy 0.1\n",
      "step 37400, training accuracy 0.02\n",
      "step 37500, training accuracy 0.1\n",
      "step 37600, training accuracy 0.08\n",
      "step 37700, training accuracy 0.1\n",
      "step 37800, training accuracy 0.16\n",
      "step 37900, training accuracy 0.2\n",
      "step 38000, training accuracy 0.1\n",
      "step 38100, training accuracy 0.08\n",
      "step 38200, training accuracy 0.06\n",
      "step 38300, training accuracy 0.16\n",
      "step 38400, training accuracy 0.1\n",
      "step 38500, training accuracy 0.16\n",
      "step 38600, training accuracy 0.12\n",
      "step 38700, training accuracy 0.16\n",
      "step 38800, training accuracy 0.06\n",
      "step 38900, training accuracy 0.1\n",
      "step 39000, training accuracy 0.12\n",
      "step 39100, training accuracy 0.04\n",
      "step 39200, training accuracy 0.02\n",
      "step 39300, training accuracy 0.1\n",
      "step 39400, training accuracy 0.1\n",
      "step 39500, training accuracy 0.08\n",
      "step 39600, training accuracy 0.06\n",
      "step 39700, training accuracy 0.14\n",
      "step 39800, training accuracy 0.1\n",
      "step 39900, training accuracy 0.1\n",
      "step 40000, training accuracy 0.12\n",
      "step 40100, training accuracy 0.12\n",
      "step 40200, training accuracy 0.04\n",
      "step 40300, training accuracy 0.24\n",
      "step 40400, training accuracy 0.06\n",
      "step 40500, training accuracy 0.1\n",
      "step 40600, training accuracy 0.08\n",
      "step 40700, training accuracy 0.08\n",
      "step 40800, training accuracy 0.08\n",
      "step 40900, training accuracy 0.16\n",
      "step 41000, training accuracy 0.12\n",
      "step 41100, training accuracy 0.2\n",
      "step 41200, training accuracy 0.08\n",
      "step 41300, training accuracy 0.14\n",
      "step 41400, training accuracy 0.1\n",
      "step 41500, training accuracy 0.1\n",
      "step 41600, training accuracy 0.12\n",
      "step 41700, training accuracy 0.1\n",
      "step 41800, training accuracy 0.06\n",
      "step 41900, training accuracy 0.14\n",
      "step 42000, training accuracy 0.14\n",
      "step 42100, training accuracy 0.16\n",
      "step 42200, training accuracy 0.1\n",
      "step 42300, training accuracy 0.12\n",
      "step 42400, training accuracy 0.08\n",
      "step 42500, training accuracy 0.12\n",
      "step 42600, training accuracy 0.14\n",
      "step 42700, training accuracy 0.12\n",
      "step 42800, training accuracy 0.16\n",
      "step 42900, training accuracy 0.18\n",
      "step 43000, training accuracy 0.08\n",
      "step 43100, training accuracy 0.1\n",
      "step 43200, training accuracy 0.1\n",
      "step 43300, training accuracy 0.14\n",
      "step 43400, training accuracy 0.14\n",
      "step 43500, training accuracy 0.1\n",
      "step 43600, training accuracy 0.08\n",
      "step 43700, training accuracy 0.08\n",
      "step 43800, training accuracy 0.14\n",
      "step 43900, training accuracy 0.12\n",
      "step 44000, training accuracy 0.1\n",
      "step 44100, training accuracy 0.1\n",
      "step 44200, training accuracy 0.12\n",
      "step 44300, training accuracy 0.08\n",
      "step 44400, training accuracy 0.04\n",
      "step 44500, training accuracy 0.14\n",
      "step 44600, training accuracy 0.06\n",
      "step 44700, training accuracy 0.08\n",
      "step 44800, training accuracy 0.14\n",
      "step 44900, training accuracy 0.14\n",
      "step 45000, training accuracy 0.08\n",
      "step 45100, training accuracy 0.12\n",
      "step 45200, training accuracy 0.1\n",
      "step 45300, training accuracy 0.18\n",
      "step 45400, training accuracy 0.14\n",
      "step 45500, training accuracy 0.16\n",
      "step 45600, training accuracy 0.04\n",
      "step 45700, training accuracy 0.06\n",
      "step 45800, training accuracy 0.22\n",
      "step 45900, training accuracy 0.18\n",
      "step 46000, training accuracy 0.16\n",
      "step 46100, training accuracy 0.18\n",
      "step 46200, training accuracy 0.08\n",
      "step 46300, training accuracy 0.02\n",
      "step 46400, training accuracy 0.18\n",
      "step 46500, training accuracy 0.18\n",
      "step 46600, training accuracy 0.16\n",
      "step 46700, training accuracy 0.08\n",
      "step 46800, training accuracy 0.06\n",
      "step 46900, training accuracy 0.18\n",
      "step 47000, training accuracy 0.08\n",
      "step 47100, training accuracy 0.02\n",
      "step 47200, training accuracy 0.04\n",
      "step 47300, training accuracy 0.1\n",
      "step 47400, training accuracy 0.26\n",
      "step 47500, training accuracy 0.06\n",
      "step 47600, training accuracy 0.16\n",
      "step 47700, training accuracy 0.14\n",
      "step 47800, training accuracy 0.06\n",
      "step 47900, training accuracy 0.2\n",
      "step 48000, training accuracy 0.12\n",
      "step 48100, training accuracy 0.14\n",
      "step 48200, training accuracy 0.12\n",
      "step 48300, training accuracy 0.12\n",
      "step 48400, training accuracy 0.08\n",
      "step 48500, training accuracy 0.16\n",
      "step 48600, training accuracy 0.08\n",
      "step 48700, training accuracy 0.1\n",
      "step 48800, training accuracy 0.18\n",
      "step 48900, training accuracy 0.12\n",
      "step 49000, training accuracy 0.12\n",
      "step 49100, training accuracy 0.1\n",
      "step 49200, training accuracy 0.1\n",
      "step 49300, training accuracy 0.14\n",
      "step 49400, training accuracy 0.12\n",
      "step 49500, training accuracy 0.18\n",
      "step 49600, training accuracy 0.04\n",
      "step 49700, training accuracy 0.18\n",
      "step 49800, training accuracy 0.04\n",
      "step 49900, training accuracy 0.16\n",
      "step 50000, training accuracy 0.14\n",
      "step 50100, training accuracy 0.12\n",
      "step 50200, training accuracy 0.14\n",
      "step 50300, training accuracy 0.12\n",
      "step 50400, training accuracy 0.1\n",
      "step 50500, training accuracy 0.1\n",
      "step 50600, training accuracy 0.12\n",
      "step 50700, training accuracy 0.06\n",
      "step 50800, training accuracy 0.04\n",
      "step 50900, training accuracy 0.26\n",
      "step 51000, training accuracy 0.12\n",
      "step 51100, training accuracy 0.14\n",
      "step 51200, training accuracy 0.06\n",
      "step 51300, training accuracy 0.18\n",
      "step 51400, training accuracy 0.12\n",
      "step 51500, training accuracy 0.18\n",
      "step 51600, training accuracy 0.08\n",
      "step 51700, training accuracy 0.08\n",
      "step 51800, training accuracy 0.14\n",
      "step 51900, training accuracy 0.08\n",
      "step 52000, training accuracy 0.12\n",
      "step 52100, training accuracy 0.1\n",
      "step 52200, training accuracy 0.1\n",
      "step 52300, training accuracy 0.08\n",
      "step 52400, training accuracy 0.06\n",
      "step 52500, training accuracy 0.1\n",
      "step 52600, training accuracy 0.14\n",
      "step 52700, training accuracy 0.14\n",
      "step 52800, training accuracy 0.14\n",
      "step 52900, training accuracy 0.08\n",
      "step 53000, training accuracy 0.16\n",
      "step 53100, training accuracy 0.1\n",
      "step 53200, training accuracy 0.1\n",
      "step 53300, training accuracy 0.06\n",
      "step 53400, training accuracy 0.12\n",
      "step 53500, training accuracy 0.08\n",
      "step 53600, training accuracy 0.14\n",
      "step 53700, training accuracy 0.14\n",
      "step 53800, training accuracy 0.2\n",
      "step 53900, training accuracy 0.14\n",
      "step 54000, training accuracy 0.14\n",
      "step 54100, training accuracy 0.04\n",
      "step 54200, training accuracy 0.1\n",
      "step 54300, training accuracy 0.18\n",
      "step 54400, training accuracy 0.26\n",
      "step 54500, training accuracy 0.18\n",
      "step 54600, training accuracy 0.08\n",
      "step 54700, training accuracy 0.1\n",
      "step 54800, training accuracy 0.12\n",
      "step 54900, training accuracy 0.12\n",
      "step 55000, training accuracy 0.06\n",
      "step 55100, training accuracy 0.12\n",
      "step 55200, training accuracy 0.12\n",
      "step 55300, training accuracy 0.2\n",
      "step 55400, training accuracy 0.16\n",
      "step 55500, training accuracy 0.04\n",
      "step 55600, training accuracy 0.1\n",
      "step 55700, training accuracy 0.16\n",
      "step 55800, training accuracy 0.1\n",
      "step 55900, training accuracy 0.12\n",
      "step 56000, training accuracy 0.2\n",
      "step 56100, training accuracy 0.18\n",
      "step 56200, training accuracy 0.06\n",
      "step 56300, training accuracy 0.08\n",
      "step 56400, training accuracy 0.1\n",
      "step 56500, training accuracy 0.12\n",
      "step 56600, training accuracy 0.2\n",
      "step 56700, training accuracy 0.1\n",
      "step 56800, training accuracy 0.06\n",
      "step 56900, training accuracy 0.14\n",
      "step 57000, training accuracy 0.16\n",
      "step 57100, training accuracy 0.12\n",
      "step 57200, training accuracy 0.14\n",
      "step 57300, training accuracy 0.1\n",
      "step 57400, training accuracy 0.06\n",
      "step 57500, training accuracy 0.1\n",
      "step 57600, training accuracy 0.18\n",
      "step 57700, training accuracy 0.08\n",
      "step 57800, training accuracy 0.18\n",
      "step 57900, training accuracy 0.06\n",
      "step 58000, training accuracy 0.14\n",
      "step 58100, training accuracy 0.12\n",
      "step 58200, training accuracy 0.04\n",
      "step 58300, training accuracy 0.14\n",
      "step 58400, training accuracy 0.08\n",
      "step 58500, training accuracy 0.08\n",
      "step 58600, training accuracy 0.16\n",
      "step 58700, training accuracy 0.18\n",
      "step 58800, training accuracy 0.08\n",
      "step 58900, training accuracy 0.1\n",
      "step 59000, training accuracy 0.2\n",
      "step 59100, training accuracy 0.14\n",
      "step 59200, training accuracy 0.1\n",
      "step 59300, training accuracy 0.22\n",
      "step 59400, training accuracy 0.14\n",
      "step 59500, training accuracy 0.06\n",
      "step 59600, training accuracy 0.22\n",
      "step 59700, training accuracy 0.06\n",
      "step 59800, training accuracy 0.04\n",
      "step 59900, training accuracy 0.08\n",
      "step 60000, training accuracy 0.1\n",
      "step 60100, training accuracy 0.12\n",
      "step 60200, training accuracy 0.1\n",
      "step 60300, training accuracy 0.14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0287e08cd70b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step %d, training accuracy %g\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;31m#   summary, _, outshape, wc111, bc111, yop, yr, yopv, yc, hp1, hp2 = sess.run([merged_summary_op,train_step,out_shape, W_conv1, b_conv1, y_outer_product, y_raw, y_outer_product_vec, y_conv, h_pool1, h_pool2], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m   \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwc111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged_summary_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_conv1_bnn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_conv1_bnn1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_pool1_bnn1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m   \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;31m#   print(\"out shape\", outshape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()    \n",
    "   \n",
    "batch_size = 50\n",
    "    \n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def max_pool_4x4(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 4, 4, 1],\n",
    "                        strides=[1, 4, 4, 1], padding='SAME')\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')    \n",
    "    \n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=1e-4)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('Wx_B') as scope:\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 224, 224, 3])\n",
    "    x_batch_size = tf.shape(x)[0]\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "    x_image = tf.reshape(x, [-1,224, 224, 3])\n",
    "\n",
    "    \n",
    "    with tf.name_scope('bilinear_model_1') as scope:\n",
    "        W_conv1_bnn1 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1_bnn1 = bias_variable([32])\n",
    "        h_conv1_bnn1 = tf.nn.relu(conv2d(x_image, W_conv1_bnn1) + b_conv1_bnn1)\n",
    "        h_pool1_bnn1 = max_pool_2x2(h_conv1_bnn1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_conv2_bnn1 = weight_variable([5, 5, 32, 40])\n",
    "        b_conv2_bnn1 = bias_variable([40])\n",
    "        h_conv2_bnn1 = tf.nn.relu(conv2d(h_pool1_bnn1, W_conv2_bnn1) + b_conv2_bnn1)\n",
    "        h_pool2_bnn1 = max_pool_2x2(h_conv2_bnn1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_conv3_bnn1 = weight_variable([5, 5, 40, 16])\n",
    "        b_conv3_bnn1 = bias_variable([16])\n",
    "        h_conv3_bnn1 = tf.nn.relu(conv2d(h_pool2_bnn1, W_conv3_bnn1) + b_conv3_bnn1)\n",
    "    #     h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_fc1_bnn1 = weight_variable([56 * 56 * 16, 20])\n",
    "        b_fc1_bnn1 = bias_variable([20])\n",
    "        h_conv3_flat_bnn1 = tf.reshape(h_conv3_bnn1, [-1, 56 * 56 * 16])\n",
    "        h_fc1_bnn1 = tf.nn.relu(tf.matmul(h_conv3_flat_bnn1, W_fc1_bnn1) + b_fc1_bnn1)\n",
    "\n",
    "\n",
    "\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        y_raw_bnn1 = h_fc1_bnn1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    with tf.name_scope('bilinear_model_2') as scope:\n",
    "        W_conv1_bnn2 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1_bnn2 = bias_variable([32])\n",
    "        h_conv1_bnn2 = tf.nn.relu(conv2d(x_image, W_conv1_bnn2) + b_conv1_bnn2)\n",
    "        h_pool1_bnn2 = max_pool_2x2(h_conv1_bnn2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_conv2_bnn2 = weight_variable([5, 5, 32, 42])\n",
    "        b_conv2_bnn2 = bias_variable([42])\n",
    "        h_conv2_bnn2 = tf.nn.relu(conv2d(h_pool1_bnn2, W_conv2_bnn2) + b_conv2_bnn2)\n",
    "        h_pool2_bnn2 = max_pool_2x2(h_conv2_bnn2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_conv3_bnn2 = weight_variable([5, 5, 42, 16])\n",
    "        b_conv3_bnn2 = bias_variable([16])\n",
    "        h_conv3_bnn2 = tf.nn.relu(conv2d(h_pool2_bnn2, W_conv3_bnn2) + b_conv3_bnn2)\n",
    "    #     h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_fc1_bnn2 = weight_variable([56 * 56 * 16, 20])\n",
    "        b_fc1_bnn2 = bias_variable([20])\n",
    "        h_conv3_flat_bnn2 = tf.reshape(h_conv3_bnn2, [-1, 56 * 56 * 16])\n",
    "        h_fc1_bnn2 = tf.nn.relu(tf.matmul(h_conv3_flat_bnn2, W_fc1_bnn2) + b_fc1_bnn2)\n",
    "\n",
    "\n",
    "\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        y_raw_bnn2 = h_fc1_bnn2\n",
    "\n",
    "\n",
    "\n",
    "    with tf.name_scope('outer_product') as scope:\n",
    "\n",
    "\n",
    "        def batch_outer_product(x, y):\n",
    "            print(\"it begins\")\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "\n",
    "    #         x_transposed = tf.transpose(x)\n",
    "            x_transposed = x\n",
    "    #         print x_transposed.get_shape()  # ==> [N, U]\n",
    "\n",
    "            x_transposed_as_matrix_batch = tf.expand_dims(x_transposed, 2)\n",
    "            print(x_transposed_as_matrix_batch.shape)\n",
    "    #         print x_transposed_as_matrix_batch.get_shape()  # ==> [N, U, 1]\n",
    "\n",
    "            y_as_matrix_batch = tf.expand_dims(y, 1)\n",
    "            print(y_as_matrix_batch.shape)\n",
    "\n",
    "    #         print y_as_matrix_batch.get_shape()  # ==> [N, 1, V]\n",
    "\n",
    "            result = tf.matmul(x_transposed_as_matrix_batch, y_as_matrix_batch)\n",
    "\n",
    "            print(result.shape)\n",
    "    #         result = tf.batch_matmul(x_transposed_as_matrix_batch, y_as_matrix_batch)\n",
    "        #         print result.get_shape()  # ==> [N, U, V]\n",
    "            print(\"It ends\")\n",
    "            return result\n",
    "\n",
    "\n",
    "\n",
    "        #  shape 50 x 10, to 50 x 100\n",
    "        print(y_raw_bnn1.shape)\n",
    "        y_outer_product = batch_outer_product(y_raw_bnn1, y_raw_bnn2)\n",
    "        print(y_outer_product.shape)\n",
    "\n",
    "\n",
    "    #     #  shape = 50 x 100\n",
    "        y_outer_product_vec = tf.nn.relu(tf.sqrt(tf.reshape(y_outer_product, [x_batch_size,-1])))\n",
    "        print(y_outer_product_vec.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #  final fc layer transformation to 10 classes\n",
    "    W_fc3 = weight_variable([400, 10])\n",
    "    b_fc3 = bias_variable([10])\n",
    "    y_fc3 = tf.matmul(y_outer_product_vec, W_fc3) + b_fc3\n",
    "\n",
    "    \n",
    "    y_conv=tf.nn.softmax(y_fc3)\n",
    "    out_shape = tf.shape(y_conv)\n",
    "    print(y_conv.shape)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#  FINE AFTER HERE\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def l2_loss(tensor_inst):\n",
    "    return tf.reduce_sum(tensor_inst ** 2)\n",
    "beta = 0.0001\n",
    "\n",
    "with tf.name_scope('cost') as scope:\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1])) + \\\n",
    "                beta*l2_loss(W_conv1_bnn1) +\\\n",
    "                beta*l2_loss(b_conv1_bnn1) +\\\n",
    "                beta*l2_loss(W_conv2_bnn1) +\\\n",
    "                beta*l2_loss(b_conv2_bnn1) +\\\n",
    "                beta*l2_loss(W_conv3_bnn1) +\\\n",
    "                beta*l2_loss(b_conv3_bnn1) +\\\n",
    "                beta*l2_loss(W_fc1_bnn1) +\\\n",
    "                beta*l2_loss(b_fc1_bnn1) +\\\n",
    "                beta*l2_loss(W_conv1_bnn2) +\\\n",
    "                beta*l2_loss(b_conv1_bnn2) +\\\n",
    "                beta*l2_loss(W_conv2_bnn2) +\\\n",
    "                beta*l2_loss(b_conv2_bnn2) +\\\n",
    "                beta*l2_loss(W_conv3_bnn2) +\\\n",
    "                beta*l2_loss(b_conv3_bnn2) +\\\n",
    "                beta*l2_loss(W_fc1_bnn2) +\\\n",
    "                beta*l2_loss(b_fc1_bnn2) +\\\n",
    "                beta*l2_loss(W_fc3) +\\\n",
    "                beta*l2_loss(b_fc3)\n",
    "#                 beta*l2_loss(W_fc2) +\\\n",
    "#                 beta*l2_loss(b_fc2) +\\\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('optimizer') as scope:\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('accuracy') as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  summary writers for debugging\n",
    "summary_writer = tf.summary.FileWriter( '/home/tuna/Projects/CS678/Deep_Learning_Project_2/tf_logs/full_bilinear_test_birds_1', graph=sess.graph )\n",
    "acc_summary = tf.summary.scalar( 'accuracy', accuracy )\n",
    "loss_summary = tf.summary.scalar( 'loss', cross_entropy )\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "#   batch = mnist.train.next_batch(batch_size)\n",
    "  batch_xs, batch_ys = get_next_batch(train_data_original, train_classes_ohe, batch_size)\n",
    "\n",
    "    \n",
    "    \n",
    "#   print(\"Batch\", i)\n",
    "  if i%1 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "#   summary, _, outshape, wc111, bc111, yop, yr, yopv, yc, hp1, hp2 = sess.run([merged_summary_op,train_step,out_shape, W_conv1, b_conv1, y_outer_product, y_raw, y_outer_product_vec, y_conv, h_pool1, h_pool2], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "  summary, _, outshape, wc111, bc111, yc, hp1 = sess.run([merged_summary_op,train_step,out_shape, W_conv1_bnn1, b_conv1_bnn1,  y_conv, h_pool1_bnn1], feed_dict={x:batch_xs, y_: batch_ys, keep_prob: 0.5})\n",
    "  summary_writer.add_summary(summary, i)\n",
    "#   print(\"out shape\", outshape)\n",
    "#   print(\"wc1\", wc111)\n",
    "#   print(\"bc1\", bc111)\n",
    "#   print(\"hp1\", hp1)\n",
    "#   print(\"hp2\", hp2)\n",
    "#   print(\"yr\", yr)\n",
    "#   print(\"yop\", yop)\n",
    "#   print(\"yopv\", yopv)\n",
    "#   print(\"yc\", yc)\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x:test_data_original, y_: test_classes_ohe, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "summary_writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()    \n",
    "   \n",
    "batch_size = 50\n",
    "    \n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "#     return max_pool_custom_crazy_slow(x)\n",
    "\n",
    "\n",
    "# def max_pool_custom_crazy_slow(x, batch_size= 50):\n",
    "#   print(x.shape)\n",
    "#   N, H, W, C = x.shape\n",
    "#   N = batch_size\n",
    "#   pool_height, pool_width, stride = 2, 2, 2\n",
    "#   assert (H - pool_height) % stride == 0\n",
    "#   assert (W - pool_width) % stride == 0\n",
    "\n",
    "\n",
    "#   out_height = (H - pool_height) / stride + 1\n",
    "#   out_width = (W - pool_width) / stride + 1\n",
    "  \n",
    "  \n",
    "    \n",
    "#   output = []\n",
    "\n",
    "# #   out = tf.zeros(tf.shape(x))\n",
    "\n",
    "# #   out = np.zeros((N, out_height, out_width, C))\n",
    "#   #  for each channel\n",
    "#   print(\"1\")\n",
    "#   for c in xrange(C):\n",
    "#       print(c)\n",
    "#       #  for each passed image\n",
    "#       for n in xrange(N):\n",
    "#           idx_i = 0\n",
    "#           for i in xrange(pool_height, H+1, stride):\n",
    "#               idx_j = 0\n",
    "#               for j in xrange(pool_width, W+1, stride):\n",
    "#                   field = x[n,i-pool_height:i,j-pool_width:j,c]\n",
    "#                   output.append(tf.reduce_max(field))\n",
    "# #                   out[n,idx_i, idx_j, c] = tf.reduce_max(field)\n",
    "#                   idx_j += 1\n",
    "#               idx_i += 1\n",
    "            \n",
    "#   output = tf.reshape(tf.stack(output), [N, H, W, C])  ## second is shape\n",
    "            \n",
    "#   return output\n",
    "\n",
    "    \n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#     return conv_forward_naive(x, W)\n",
    "\n",
    "\n",
    "# def conv2d(x, W, HH,WW,C,F):\n",
    "# #   return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#     return conv_forward_naive(x, W, HH,WW,C,F)\n",
    "\n",
    "# def conv_forward_naive(x, w, HH,WW,C,F,  batch_size=50):\n",
    "#   \"\"\"\n",
    "#   A naive implementation of the forward pass for a convolutional layer.\n",
    "#   The input consists of N data points, each with C channels, height H and width\n",
    "#   W. We convolve each input with F different filters, where each filter spans\n",
    "#   all C channels and has height HH and width WW.\n",
    "#   Input:\n",
    "#   - x: Input data of shape (N, C, H, W)\n",
    "#   - w: Filter weights of shape (F, C, HH, WW)\n",
    "#   - b: Biases, of shape (F,)\n",
    "#   - conv_param: A dictionary with the following keys:\n",
    "#     - 'stride': The number of pixels between adjacent receptive fields in the\n",
    "#       horizontal and vertical directions.\n",
    "#     - 'pad': The number of pixels that will be used to zero-pad the input.\n",
    "#   Returns a tuple of:\n",
    "#   - out: Output data, of shape (N, F, H', W') where H' and W' are given by\n",
    "#     H' = 1 + (H + 2 * pad - HH) / stride\n",
    "#     W' = 1 + (W + 2 * pad - WW) / stride\n",
    "#   - cache: (x, w, b, conv_param)\n",
    "#   \"\"\"\n",
    "\n",
    "#   N, H, W, C = x.get_shape().as_list() \n",
    "# #   HH,WW,C,F = w.shape\n",
    "#   stride, pad = 1, 1\n",
    "#   print(x.shape)\n",
    "#   N = batch_size\n",
    "#   H_prime = 1. + float(H + 2 * pad - HH) / float(stride)\n",
    "#   W_prime = 1. + float(W + 2 * pad - WW) / float(stride)\n",
    "#   assert H_prime % 1 == 0\n",
    "#   assert W_prime % 1 == 0\n",
    "#   H_prime,W_prime = int(H_prime), int(W_prime)\n",
    "\n",
    "\n",
    "# #   # pad input array\n",
    "# #   x_padded = np.pad(x, ((0,0), (0,0), (pad, pad), (pad, pad)), 'constant')\n",
    "# #   H_padded, W_padded = x_padded.shape[2], x_padded.shape[3]\n",
    "\n",
    "#   #  no padding\n",
    "#   x_padded = x\n",
    "#   H_padded = H\n",
    "#   W_padded = W\n",
    "\n",
    "\n",
    "#   # naive implementation of im2col\n",
    "# #   x_cols = None\n",
    "#   print(\"bob\")\n",
    "#   x_cols = []\n",
    "#   for i in xrange(HH, H_padded+1, stride):\n",
    "#     print(i)\n",
    "#     for j in xrange(WW, W_padded+1, stride):\n",
    "#       for n in xrange(N):\n",
    "#         field = tf.reshape(x_padded[n,i-HH:i, j-WW:j,:], (1,C*HH*WW))    \n",
    "#         if x_cols is None:\n",
    "# #             field = tf.expand_dims(field, 0)\n",
    "# #             x_cols = field\n",
    "#           x_cols.append(field)\n",
    "#         else:\n",
    "# #             field = tf.expand_dims(field, 0)\n",
    "# #             x_cols = tf.stack((x_cols, field))\n",
    "#           x_cols.append(field)\n",
    "\n",
    "    \n",
    "#   #  every n (at HH, WW, w/ c), then every WW, then every HH\n",
    "    \n",
    "    \n",
    "#   x_cols = tf.stack(x_cols)\n",
    "  \n",
    "#   # x_cols shape: (HH * WW * C) x (H_prime * W_prime * N)\n",
    "#   x_cols = tf.transpose(x_cols)\n",
    "\n",
    "#   #w2col, get w into shape of (F) x (HH * WW * C) \n",
    "#   w_cols = tf.reshape(w, (F, C*HH *WW))\n",
    "  \n",
    "  \n",
    "#   # out_cols shape = (F) x (H_prime * W_prime * N)\n",
    "#   out_cols = np.dot(w_cols, x_cols)\n",
    "\n",
    "#   # out shape = N x F x H' x W'\n",
    "#   out = tf.reshape(out_cols, (F, H_prime, W_prime, N))\n",
    "# #   out = out.transpose(3, 0, 1, 2) # (N, F, H', W')\n",
    "#   out = out.transpose(3, 1, 2, 0) # (N, F, H', W')\n",
    "\n",
    "\n",
    "#   return out\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def weight_variable(shape, name=None):\n",
    "  if name is not None:\n",
    "    initial = tf.truncated_normal(shape, stddev=1e-4)\n",
    "    return tf.Variable(initial, name=name)\n",
    "  else:\n",
    "    initial = tf.truncated_normal(shape, stddev=1e-4)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, name=None):\n",
    "  if name is not None:\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "  else:\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n",
      "step 0, training accuracy 0.04\n",
      "step 100, training accuracy 0.12\n",
      "step 200, training accuracy 0.16\n",
      "step 300, training accuracy 0.14\n",
      "step 400, training accuracy 0.12\n",
      "step 500, training accuracy 0.18\n",
      "step 600, training accuracy 0.16\n",
      "step 700, training accuracy 0.24\n",
      "step 800, training accuracy 0.22\n",
      "step 900, training accuracy 0.16\n",
      "step 1000, training accuracy 0.32\n",
      "step 1100, training accuracy 0.2\n",
      "step 1200, training accuracy 0.34\n",
      "step 1300, training accuracy 0.4\n",
      "step 1400, training accuracy 0.52\n",
      "step 1500, training accuracy 0.56\n",
      "step 1600, training accuracy 0.68\n",
      "step 1700, training accuracy 0.54\n",
      "step 1800, training accuracy 0.66\n",
      "step 1900, training accuracy 0.72\n",
      "step 2000, training accuracy 0.84\n",
      "step 2100, training accuracy 0.74\n",
      "step 2200, training accuracy 0.78\n",
      "step 2300, training accuracy 0.72\n",
      "step 2400, training accuracy 0.76\n",
      "step 2500, training accuracy 0.8\n",
      "step 2600, training accuracy 0.78\n",
      "step 2700, training accuracy 0.74\n",
      "step 2800, training accuracy 0.9\n",
      "step 2900, training accuracy 0.78\n",
      "step 3000, training accuracy 0.78\n",
      "step 3100, training accuracy 0.74\n",
      "step 3200, training accuracy 0.92\n",
      "step 3300, training accuracy 0.82\n",
      "step 3400, training accuracy 0.84\n",
      "step 3500, training accuracy 0.72\n",
      "step 3600, training accuracy 0.8\n",
      "step 3700, training accuracy 0.8\n",
      "step 3800, training accuracy 0.88\n",
      "step 3900, training accuracy 0.88\n",
      "step 4000, training accuracy 0.76\n",
      "step 4100, training accuracy 0.86\n",
      "step 4200, training accuracy 0.9\n",
      "step 4300, training accuracy 0.8\n",
      "step 4400, training accuracy 0.84\n",
      "step 4500, training accuracy 0.84\n",
      "step 4600, training accuracy 0.86\n",
      "step 4700, training accuracy 0.86\n",
      "step 4800, training accuracy 0.92\n",
      "step 4900, training accuracy 0.92\n",
      "test accuracy 0.8543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.name_scope('Wx_B') as scope:\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_batch_size = tf.shape(x)[0]\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32], name='W_conv1')\n",
    "    b_conv1 = bias_variable([32], name='b_conv1')\n",
    "\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "#     h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 5, 5, 1, 32) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    W_conv2 = weight_variable([5, 5, 32, 32], name='W_conv2')\n",
    "    b_conv2 = bias_variable([32], name='b_conv2')\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "#     h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, 5, 5, 32, 64) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    W_fc1 = weight_variable([7 * 7 * 32, 20], name='W_fc1')\n",
    "    b_fc1 = bias_variable([20], name='b_fc1')\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*32])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    y_raw = h_fc1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # DONT SAVE THESE WEIGHTS\n",
    "    \n",
    "    #  final fc layer transformation to 10 classes\n",
    "#     W_fc3 = weight_variable([100, 10])\n",
    "    W_fc3 = weight_variable([20, 10], name='W_fc3')\n",
    "    b_fc3 = bias_variable([10], name='b_fc3')\n",
    "    y_fc3 = tf.matmul(y_raw, W_fc3) + b_fc3\n",
    "#     y_fc3 = tf.matmul(h_fc1, W_fc3) + b_fc3\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    y_conv=tf.nn.softmax(y_fc3)\n",
    "    out_shape = tf.shape(y_conv)\n",
    "    print(y_conv.shape)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#  set up saver\n",
    "saver = tf.train.Saver({\"Wx_B/W_conv1\": W_conv1, \"Wx_B/b_conv1\": b_conv1, \"Wx_B/W_conv2\": W_conv2, \"Wx_B/b_conv2\": b_conv2,\n",
    "                       \"Wx_B/W_fc1\": W_fc1, \"Wx_B/b_fc1\": b_fc1,})\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "saver.restore(sess, \"/tmp/model2.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def l2_loss(tensor_inst):\n",
    "    return tf.reduce_sum(tensor_inst ** 2)\n",
    "beta = 0.0001\n",
    "\n",
    "with tf.name_scope('cost') as scope:\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1])) + \\\n",
    "                beta*l2_loss(W_conv1) +\\\n",
    "                beta*l2_loss(W_conv2) +\\\n",
    "                beta*l2_loss(b_conv1) +\\\n",
    "                beta*l2_loss(b_conv2) +\\\n",
    "                beta*l2_loss(W_fc1) +\\\n",
    "                beta*l2_loss(b_fc1) +\\\n",
    "                beta*l2_loss(W_fc3) +\\\n",
    "                beta*l2_loss(b_fc3)\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('optimizer') as scope:\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('accuracy') as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  summary writers for debugging\n",
    "summary_writer = tf.summary.FileWriter( '/home/tuna/Projects/CS678/Deep_Learning_Project_2/tf_logs/4_layers_test_14_pre_train_save_', graph=sess.graph )\n",
    "acc_summary = tf.summary.scalar( 'accuracy', accuracy )\n",
    "loss_summary = tf.summary.scalar( 'loss', cross_entropy )\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5000):\n",
    "  batch = mnist.train.next_batch(batch_size)\n",
    "#   print(\"Batch\", i)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "#   summary, _, outshape, wc111, bc111, yop, yr, yopv, yc, hp1, hp2 = sess.run([merged_summary_op,train_step,out_shape, W_conv1, b_conv1, y_outer_product, y_raw, y_outer_product_vec, y_conv, h_pool1, h_pool2], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "  summary, _, outshape, wc111, bc111, yc, hp1 = sess.run([merged_summary_op,train_step,out_shape, W_conv1, b_conv1,  y_conv, h_pool1], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "  summary_writer.add_summary(summary, i)\n",
    "#   print(\"out shape\", outshape)\n",
    "#   print(\"wc1\", wc111)\n",
    "#   print(\"bc1\", bc111)\n",
    "#   print(\"hp1\", hp1)\n",
    "#   print(\"hp2\", hp2)\n",
    "#   print(\"yr\", yr)\n",
    "#   print(\"yop\", yop)\n",
    "#   print(\"yopv\", yopv)\n",
    "#   print(\"y_softmax\", yc)\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "\n",
    "#  save the weights\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, save the\n",
    "# variables to disk.\n",
    "  # Save the variables to disk.\n",
    "# save_path = saver.save(sess, \"/tmp/model2.ckpt\")\n",
    "# print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "summary_writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20)\n",
      "it begins\n",
      "(?, 20)\n",
      "(?, 20)\n",
      "(?, 20, 1)\n",
      "(?, 1, 20)\n",
      "(?, 20, 20)\n",
      "It ends\n",
      "(?, 20, 20)\n",
      "(?, ?)\n",
      "(?, 10)\n",
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.12\n",
      "step 200, training accuracy 0.16\n",
      "step 300, training accuracy 0.14\n",
      "step 400, training accuracy 0.12\n",
      "step 500, training accuracy 0.1\n",
      "step 600, training accuracy 0.12\n",
      "step 700, training accuracy 0.12\n",
      "step 800, training accuracy 0.12\n",
      "step 900, training accuracy 0.06\n",
      "step 1000, training accuracy 0.12\n",
      "step 1100, training accuracy 0.2\n",
      "step 1200, training accuracy 0.1\n",
      "step 1300, training accuracy 0.04\n",
      "step 1400, training accuracy 0.06\n",
      "step 1500, training accuracy 0.12\n",
      "step 1600, training accuracy 0.06\n",
      "step 1700, training accuracy 0.16\n",
      "step 1800, training accuracy 0.22\n",
      "step 1900, training accuracy 0.04\n",
      "step 2000, training accuracy 0.12\n",
      "step 2100, training accuracy 0.2\n",
      "step 2200, training accuracy 0.08\n",
      "step 2300, training accuracy 0.18\n",
      "step 2400, training accuracy 0.1\n",
      "step 2500, training accuracy 0.1\n",
      "step 2600, training accuracy 0.08\n",
      "step 2700, training accuracy 0.12\n",
      "step 2800, training accuracy 0.12\n",
      "step 2900, training accuracy 0.14\n",
      "step 3000, training accuracy 0.04\n",
      "step 3100, training accuracy 0.18\n",
      "step 3200, training accuracy 0.08\n",
      "step 3300, training accuracy 0.14\n",
      "step 3400, training accuracy 0.12\n",
      "step 3500, training accuracy 0.14\n",
      "step 3600, training accuracy 0.04\n",
      "step 3700, training accuracy 0.06\n",
      "step 3800, training accuracy 0.04\n",
      "step 3900, training accuracy 0.06\n",
      "step 4000, training accuracy 0.14\n",
      "step 4100, training accuracy 0.1\n",
      "step 4200, training accuracy 0.1\n",
      "step 4300, training accuracy 0.22\n",
      "step 4400, training accuracy 0.08\n",
      "step 4500, training accuracy 0.06\n",
      "step 4600, training accuracy 0.14\n",
      "step 4700, training accuracy 0.12\n",
      "step 4800, training accuracy 0.08\n",
      "step 4900, training accuracy 0.1\n",
      "step 5000, training accuracy 0.14\n",
      "step 5100, training accuracy 0.16\n",
      "step 5200, training accuracy 0.2\n",
      "step 5300, training accuracy 0.06\n",
      "step 5400, training accuracy 0.08\n",
      "step 5500, training accuracy 0.08\n",
      "step 5600, training accuracy 0.22\n",
      "step 5700, training accuracy 0.18\n",
      "step 5800, training accuracy 0.08\n",
      "step 5900, training accuracy 0.1\n",
      "step 6000, training accuracy 0.06\n",
      "step 6100, training accuracy 0.08\n",
      "step 6200, training accuracy 0.16\n",
      "step 6300, training accuracy 0.26\n",
      "step 6400, training accuracy 0.12\n",
      "step 6500, training accuracy 0.08\n",
      "step 6600, training accuracy 0.14\n",
      "step 6700, training accuracy 0.04\n",
      "step 6800, training accuracy 0.12\n",
      "step 6900, training accuracy 0.16\n",
      "step 7000, training accuracy 0.1\n",
      "step 7100, training accuracy 0.08\n",
      "step 7200, training accuracy 0.18\n",
      "step 7300, training accuracy 0.1\n",
      "step 7400, training accuracy 0.16\n",
      "step 7500, training accuracy 0.14\n",
      "step 7600, training accuracy 0.18\n",
      "step 7700, training accuracy 0.14\n",
      "step 7800, training accuracy 0.1\n",
      "step 7900, training accuracy 0.1\n",
      "step 8000, training accuracy 0.1\n",
      "step 8100, training accuracy 0.18\n",
      "step 8200, training accuracy 0.18\n",
      "step 8300, training accuracy 0.12\n",
      "step 8400, training accuracy 0.14\n",
      "step 8500, training accuracy 0.06\n",
      "step 8600, training accuracy 0.12\n",
      "step 8700, training accuracy 0.06\n",
      "step 8800, training accuracy 0.22\n",
      "step 8900, training accuracy 0.08\n",
      "step 9000, training accuracy 0.06\n",
      "step 9100, training accuracy 0.14\n",
      "step 9200, training accuracy 0.16\n",
      "step 9300, training accuracy 0.1\n",
      "step 9400, training accuracy 0.24\n",
      "step 9500, training accuracy 0.08\n",
      "step 9600, training accuracy 0.1\n",
      "step 9700, training accuracy 0.04\n",
      "step 9800, training accuracy 0.04\n",
      "step 9900, training accuracy 0.1\n",
      "step 10000, training accuracy 0.06\n",
      "step 10100, training accuracy 0.08\n",
      "step 10200, training accuracy 0.22\n",
      "step 10300, training accuracy 0.1\n",
      "step 10400, training accuracy 0.12\n",
      "step 10500, training accuracy 0.14\n",
      "step 10600, training accuracy 0.1\n",
      "step 10700, training accuracy 0.1\n",
      "step 10800, training accuracy 0.08\n",
      "step 10900, training accuracy 0.1\n",
      "step 11000, training accuracy 0.06\n",
      "step 11100, training accuracy 0.04\n",
      "step 11200, training accuracy 0.16\n",
      "step 11300, training accuracy 0.06\n",
      "step 11400, training accuracy 0.1\n",
      "step 11500, training accuracy 0.1\n",
      "step 11600, training accuracy 0.16\n",
      "step 11700, training accuracy 0.14\n",
      "step 11800, training accuracy 0.1\n",
      "step 11900, training accuracy 0.08\n",
      "step 12000, training accuracy 0.14\n",
      "step 12100, training accuracy 0.04\n",
      "step 12200, training accuracy 0.12\n",
      "step 12300, training accuracy 0.1\n",
      "step 12400, training accuracy 0.04\n",
      "step 12500, training accuracy 0.08\n",
      "step 12600, training accuracy 0.08\n",
      "step 12700, training accuracy 0\n",
      "step 12800, training accuracy 0.1\n",
      "step 12900, training accuracy 0.12\n",
      "step 13000, training accuracy 0.1\n",
      "step 13100, training accuracy 0.1\n",
      "step 13200, training accuracy 0.24\n",
      "step 13300, training accuracy 0.12\n",
      "step 13400, training accuracy 0.14\n",
      "step 13500, training accuracy 0.16\n",
      "step 13600, training accuracy 0.08\n",
      "step 13700, training accuracy 0.1\n",
      "step 13800, training accuracy 0.14\n",
      "step 13900, training accuracy 0.06\n",
      "step 14000, training accuracy 0.1\n",
      "step 14100, training accuracy 0.06\n",
      "step 14200, training accuracy 0.06\n",
      "step 14300, training accuracy 0.1\n",
      "step 14400, training accuracy 0.12\n",
      "step 14500, training accuracy 0.06\n",
      "step 14600, training accuracy 0.06\n",
      "step 14700, training accuracy 0.12\n",
      "step 14800, training accuracy 0.16\n",
      "step 14900, training accuracy 0.1\n",
      "step 15000, training accuracy 0.06\n",
      "step 15100, training accuracy 0.06\n",
      "step 15200, training accuracy 0.04\n",
      "step 15300, training accuracy 0.1\n",
      "step 15400, training accuracy 0.1\n",
      "step 15500, training accuracy 0.06\n",
      "step 15600, training accuracy 0.1\n",
      "step 15700, training accuracy 0.08\n",
      "step 15800, training accuracy 0.12\n",
      "step 15900, training accuracy 0.16\n",
      "step 16000, training accuracy 0.16\n",
      "step 16100, training accuracy 0.08\n",
      "step 16200, training accuracy 0.16\n",
      "step 16300, training accuracy 0.08\n",
      "step 16400, training accuracy 0.1\n",
      "step 16500, training accuracy 0.14\n",
      "step 16600, training accuracy 0.16\n",
      "step 16700, training accuracy 0.12\n",
      "step 16800, training accuracy 0.06\n",
      "step 16900, training accuracy 0.18\n",
      "step 17000, training accuracy 0.12\n",
      "step 17100, training accuracy 0.18\n",
      "step 17200, training accuracy 0.12\n",
      "step 17300, training accuracy 0.14\n",
      "step 17400, training accuracy 0.18\n",
      "step 17500, training accuracy 0.18\n",
      "step 17600, training accuracy 0.14\n",
      "step 17700, training accuracy 0.14\n",
      "step 17800, training accuracy 0.12\n",
      "step 17900, training accuracy 0.16\n",
      "step 18000, training accuracy 0.2\n",
      "step 18100, training accuracy 0.12\n",
      "step 18200, training accuracy 0.1\n",
      "step 18300, training accuracy 0.12\n",
      "step 18400, training accuracy 0.18\n",
      "step 18500, training accuracy 0.06\n",
      "step 18600, training accuracy 0.14\n",
      "step 18700, training accuracy 0.12\n",
      "step 18800, training accuracy 0.16\n",
      "step 18900, training accuracy 0.06\n",
      "step 19000, training accuracy 0.12\n",
      "step 19100, training accuracy 0.16\n",
      "step 19200, training accuracy 0.04\n",
      "step 19300, training accuracy 0.08\n",
      "step 19400, training accuracy 0.14\n",
      "step 19500, training accuracy 0.12\n",
      "step 19600, training accuracy 0.1\n",
      "step 19700, training accuracy 0.14\n",
      "step 19800, training accuracy 0.16\n",
      "step 19900, training accuracy 0.06\n",
      "step 20000, training accuracy 0.12\n",
      "step 20100, training accuracy 0.16\n",
      "step 20200, training accuracy 0.1\n",
      "step 20300, training accuracy 0.1\n",
      "step 20400, training accuracy 0.1\n",
      "step 20500, training accuracy 0.12\n",
      "step 20600, training accuracy 0.12\n",
      "step 20700, training accuracy 0.16\n",
      "step 20800, training accuracy 0.16\n",
      "step 20900, training accuracy 0.02\n",
      "step 21000, training accuracy 0.08\n",
      "step 21100, training accuracy 0.02\n",
      "step 21200, training accuracy 0.1\n",
      "step 21300, training accuracy 0.04\n",
      "step 21400, training accuracy 0.12\n",
      "step 21500, training accuracy 0.06\n",
      "step 21600, training accuracy 0.14\n",
      "step 21700, training accuracy 0.14\n",
      "step 21800, training accuracy 0.1\n",
      "step 21900, training accuracy 0.1\n",
      "step 22000, training accuracy 0.12\n",
      "step 22100, training accuracy 0.18\n",
      "step 22200, training accuracy 0.2\n",
      "step 22300, training accuracy 0.12\n",
      "step 22400, training accuracy 0.12\n",
      "step 22500, training accuracy 0.14\n",
      "step 22600, training accuracy 0.1\n",
      "step 22700, training accuracy 0.1\n",
      "step 22800, training accuracy 0.1\n",
      "step 22900, training accuracy 0.02\n",
      "step 23000, training accuracy 0.12\n",
      "step 23100, training accuracy 0.1\n",
      "step 23200, training accuracy 0.1\n",
      "step 23300, training accuracy 0.12\n",
      "step 23400, training accuracy 0.08\n",
      "step 23500, training accuracy 0.2\n",
      "step 23600, training accuracy 0.18\n",
      "step 23700, training accuracy 0.04\n",
      "step 23800, training accuracy 0.12\n",
      "step 23900, training accuracy 0.12\n",
      "step 24000, training accuracy 0.06\n",
      "step 24100, training accuracy 0.1\n",
      "step 24200, training accuracy 0.16\n",
      "step 24300, training accuracy 0.12\n",
      "step 24400, training accuracy 0.06\n",
      "step 24500, training accuracy 0.04\n",
      "step 24600, training accuracy 0.12\n",
      "step 24700, training accuracy 0.14\n",
      "step 24800, training accuracy 0.08\n",
      "step 24900, training accuracy 0.2\n",
      "step 25000, training accuracy 0.08\n",
      "step 25100, training accuracy 0.12\n",
      "step 25200, training accuracy 0.14\n",
      "step 25300, training accuracy 0.1\n",
      "step 25400, training accuracy 0.02\n",
      "step 25500, training accuracy 0.06\n",
      "step 25600, training accuracy 0.12\n",
      "step 25700, training accuracy 0.14\n",
      "step 25800, training accuracy 0.08\n",
      "step 25900, training accuracy 0.02\n",
      "step 26000, training accuracy 0.06\n",
      "step 26100, training accuracy 0.22\n",
      "step 26200, training accuracy 0.14\n",
      "step 26300, training accuracy 0.12\n",
      "step 26400, training accuracy 0.1\n",
      "step 26500, training accuracy 0.06\n",
      "step 26600, training accuracy 0.12\n",
      "step 26700, training accuracy 0.1\n",
      "step 26800, training accuracy 0.12\n",
      "step 26900, training accuracy 0.12\n",
      "step 27000, training accuracy 0.08\n",
      "step 27100, training accuracy 0.14\n",
      "step 27200, training accuracy 0.12\n",
      "step 27300, training accuracy 0.12\n",
      "step 27400, training accuracy 0.22\n",
      "step 27500, training accuracy 0.06\n",
      "step 27600, training accuracy 0.06\n",
      "step 27700, training accuracy 0.08\n",
      "step 27800, training accuracy 0.18\n",
      "step 27900, training accuracy 0.18\n",
      "step 28000, training accuracy 0.16\n",
      "step 28100, training accuracy 0.08\n",
      "step 28200, training accuracy 0.2\n",
      "step 28300, training accuracy 0.14\n",
      "step 28400, training accuracy 0.02\n",
      "step 28500, training accuracy 0.12\n",
      "step 28600, training accuracy 0.04\n",
      "step 28700, training accuracy 0.1\n",
      "step 28800, training accuracy 0.1\n",
      "step 28900, training accuracy 0.08\n",
      "step 29000, training accuracy 0.16\n",
      "step 29100, training accuracy 0.2\n",
      "step 29200, training accuracy 0.12\n",
      "step 29300, training accuracy 0.12\n",
      "step 29400, training accuracy 0.1\n",
      "step 29500, training accuracy 0.1\n",
      "step 29600, training accuracy 0.1\n",
      "step 29700, training accuracy 0.16\n",
      "step 29800, training accuracy 0.06\n",
      "step 29900, training accuracy 0.14\n",
      "step 30000, training accuracy 0.14\n",
      "step 30100, training accuracy 0.1\n",
      "step 30200, training accuracy 0.1\n",
      "step 30300, training accuracy 0.22\n",
      "step 30400, training accuracy 0.12\n",
      "step 30500, training accuracy 0.1\n",
      "step 30600, training accuracy 0.18\n",
      "step 30700, training accuracy 0.08\n",
      "step 30800, training accuracy 0.02\n",
      "step 30900, training accuracy 0.08\n",
      "step 31000, training accuracy 0.12\n",
      "step 31100, training accuracy 0.18\n",
      "step 31200, training accuracy 0.1\n",
      "step 31300, training accuracy 0.08\n",
      "step 31400, training accuracy 0.1\n",
      "step 31500, training accuracy 0.1\n",
      "step 31600, training accuracy 0.06\n",
      "step 31700, training accuracy 0.1\n",
      "step 31800, training accuracy 0.04\n",
      "step 31900, training accuracy 0.12\n",
      "step 32000, training accuracy 0.14\n",
      "step 32100, training accuracy 0.16\n",
      "step 32200, training accuracy 0.08\n",
      "step 32300, training accuracy 0.1\n",
      "step 32400, training accuracy 0.12\n",
      "step 32500, training accuracy 0.2\n",
      "step 32600, training accuracy 0.14\n",
      "step 32700, training accuracy 0.16\n",
      "step 32800, training accuracy 0.12\n",
      "step 32900, training accuracy 0.04\n",
      "step 33000, training accuracy 0.12\n",
      "step 33100, training accuracy 0.1\n",
      "step 33200, training accuracy 0.1\n",
      "step 33300, training accuracy 0.14\n",
      "step 33400, training accuracy 0.12\n",
      "step 33500, training accuracy 0.08\n",
      "step 33600, training accuracy 0.06\n",
      "step 33700, training accuracy 0.12\n",
      "step 33800, training accuracy 0.16\n",
      "step 33900, training accuracy 0.1\n",
      "step 34000, training accuracy 0.14\n",
      "step 34100, training accuracy 0.12\n",
      "step 34200, training accuracy 0.24\n",
      "step 34300, training accuracy 0.1\n",
      "step 34400, training accuracy 0.16\n",
      "step 34500, training accuracy 0.08\n",
      "step 34600, training accuracy 0.16\n",
      "step 34700, training accuracy 0.08\n",
      "step 34800, training accuracy 0.08\n",
      "step 34900, training accuracy 0.08\n",
      "step 35000, training accuracy 0.14\n",
      "step 35100, training accuracy 0.12\n",
      "step 35200, training accuracy 0.18\n",
      "step 35300, training accuracy 0.08\n",
      "step 35400, training accuracy 0.08\n",
      "step 35500, training accuracy 0.08\n",
      "step 35600, training accuracy 0.1\n",
      "step 35700, training accuracy 0.1\n",
      "step 35800, training accuracy 0.1\n",
      "step 35900, training accuracy 0.14\n",
      "step 36000, training accuracy 0.24\n",
      "step 36100, training accuracy 0.06\n",
      "step 36200, training accuracy 0.02\n",
      "step 36300, training accuracy 0.14\n",
      "step 36400, training accuracy 0.1\n",
      "step 36500, training accuracy 0.08\n",
      "step 36600, training accuracy 0.16\n",
      "step 36700, training accuracy 0.08\n",
      "step 36800, training accuracy 0.1\n",
      "step 36900, training accuracy 0.14\n",
      "step 37000, training accuracy 0.08\n",
      "step 37100, training accuracy 0.14\n",
      "step 37200, training accuracy 0.2\n",
      "step 37300, training accuracy 0.12\n",
      "step 37400, training accuracy 0.14\n",
      "step 37500, training accuracy 0.12\n",
      "step 37600, training accuracy 0.1\n",
      "step 37700, training accuracy 0.1\n",
      "step 37800, training accuracy 0.12\n",
      "step 37900, training accuracy 0.12\n",
      "step 38000, training accuracy 0.2\n",
      "step 38100, training accuracy 0.06\n",
      "step 38200, training accuracy 0.14\n",
      "step 38300, training accuracy 0.06\n",
      "step 38400, training accuracy 0.08\n",
      "step 38500, training accuracy 0.06\n",
      "step 38600, training accuracy 0.14\n",
      "step 38700, training accuracy 0.16\n",
      "step 38800, training accuracy 0.12\n",
      "step 38900, training accuracy 0.14\n",
      "step 39000, training accuracy 0.14\n",
      "step 39100, training accuracy 0.08\n",
      "step 39200, training accuracy 0.14\n",
      "step 39300, training accuracy 0.1\n",
      "step 39400, training accuracy 0.06\n",
      "step 39500, training accuracy 0.1\n",
      "step 39600, training accuracy 0.16\n",
      "step 39700, training accuracy 0.04\n",
      "step 39800, training accuracy 0.18\n",
      "step 39900, training accuracy 0.08\n",
      "step 40000, training accuracy 0.1\n",
      "step 40100, training accuracy 0.16\n",
      "step 40200, training accuracy 0.1\n",
      "step 40300, training accuracy 0.18\n",
      "step 40400, training accuracy 0.12\n",
      "step 40500, training accuracy 0.12\n",
      "step 40600, training accuracy 0.14\n",
      "step 40700, training accuracy 0.08\n",
      "step 40800, training accuracy 0.14\n",
      "step 40900, training accuracy 0.18\n",
      "step 41000, training accuracy 0.06\n",
      "step 41100, training accuracy 0.16\n",
      "step 41200, training accuracy 0.08\n",
      "step 41300, training accuracy 0.08\n",
      "step 41400, training accuracy 0.1\n",
      "step 41500, training accuracy 0.14\n",
      "step 41600, training accuracy 0.04\n",
      "step 41700, training accuracy 0.12\n",
      "step 41800, training accuracy 0.16\n",
      "step 41900, training accuracy 0.06\n",
      "step 42000, training accuracy 0.08\n",
      "step 42100, training accuracy 0.1\n",
      "step 42200, training accuracy 0.16\n",
      "step 42300, training accuracy 0.16\n",
      "step 42400, training accuracy 0.18\n",
      "step 42500, training accuracy 0.06\n",
      "step 42600, training accuracy 0.1\n",
      "step 42700, training accuracy 0.1\n",
      "step 42800, training accuracy 0.08\n",
      "step 42900, training accuracy 0.06\n",
      "step 43000, training accuracy 0.08\n",
      "step 43100, training accuracy 0.1\n",
      "step 43200, training accuracy 0.16\n",
      "step 43300, training accuracy 0.14\n",
      "step 43400, training accuracy 0.06\n",
      "step 43500, training accuracy 0.14\n",
      "step 43600, training accuracy 0.1\n",
      "step 43700, training accuracy 0.08\n",
      "step 43800, training accuracy 0.18\n",
      "step 43900, training accuracy 0.1\n",
      "step 44000, training accuracy 0.1\n",
      "step 44100, training accuracy 0.12\n",
      "step 44200, training accuracy 0.06\n",
      "step 44300, training accuracy 0.18\n",
      "step 44400, training accuracy 0.06\n",
      "step 44500, training accuracy 0.12\n",
      "step 44600, training accuracy 0.06\n",
      "step 44700, training accuracy 0.1\n",
      "step 44800, training accuracy 0.1\n",
      "step 44900, training accuracy 0.1\n",
      "step 45000, training accuracy 0.12\n",
      "step 45100, training accuracy 0.08\n",
      "step 45200, training accuracy 0.16\n",
      "step 45300, training accuracy 0.12\n",
      "step 45400, training accuracy 0.02\n",
      "step 45500, training accuracy 0.08\n",
      "step 45600, training accuracy 0.1\n",
      "step 45700, training accuracy 0.06\n",
      "step 45800, training accuracy 0.12\n",
      "step 45900, training accuracy 0.16\n",
      "step 46000, training accuracy 0.12\n",
      "step 46100, training accuracy 0.06\n",
      "step 46200, training accuracy 0.1\n",
      "step 46300, training accuracy 0.18\n",
      "step 46400, training accuracy 0.14\n",
      "step 46500, training accuracy 0.16\n",
      "step 46600, training accuracy 0.08\n",
      "step 46700, training accuracy 0.08\n",
      "step 46800, training accuracy 0.18\n",
      "step 46900, training accuracy 0.14\n",
      "step 47000, training accuracy 0.1\n",
      "step 47100, training accuracy 0.1\n",
      "step 47200, training accuracy 0.06\n",
      "step 47300, training accuracy 0.2\n",
      "step 47400, training accuracy 0.06\n",
      "step 47500, training accuracy 0.16\n",
      "step 47600, training accuracy 0.08\n",
      "step 47700, training accuracy 0.1\n",
      "step 47800, training accuracy 0.14\n",
      "step 47900, training accuracy 0.16\n",
      "step 48000, training accuracy 0.1\n",
      "step 48100, training accuracy 0.04\n",
      "step 48200, training accuracy 0.16\n",
      "step 48300, training accuracy 0.18\n",
      "step 48400, training accuracy 0.14\n",
      "step 48500, training accuracy 0.06\n",
      "step 48600, training accuracy 0.08\n",
      "step 48700, training accuracy 0.08\n",
      "step 48800, training accuracy 0.22\n",
      "step 48900, training accuracy 0.14\n",
      "step 49000, training accuracy 0.12\n",
      "step 49100, training accuracy 0.16\n",
      "step 49200, training accuracy 0.08\n",
      "step 49300, training accuracy 0.06\n",
      "step 49400, training accuracy 0.12\n",
      "step 49500, training accuracy 0.1\n",
      "step 49600, training accuracy 0.06\n",
      "step 49700, training accuracy 0.12\n",
      "step 49800, training accuracy 0.08\n",
      "step 49900, training accuracy 0.1\n",
      "step 50000, training accuracy 0.2\n",
      "step 50100, training accuracy 0.16\n",
      "step 50200, training accuracy 0.06\n",
      "step 50300, training accuracy 0.1\n",
      "step 50400, training accuracy 0.08\n",
      "step 50500, training accuracy 0.08\n",
      "step 50600, training accuracy 0.12\n",
      "step 50700, training accuracy 0.12\n",
      "step 50800, training accuracy 0.08\n",
      "step 50900, training accuracy 0.06\n",
      "step 51000, training accuracy 0.02\n",
      "step 51100, training accuracy 0.1\n",
      "step 51200, training accuracy 0.08\n",
      "step 51300, training accuracy 0.16\n",
      "step 51400, training accuracy 0.08\n",
      "step 51500, training accuracy 0.08\n",
      "step 51600, training accuracy 0.06\n",
      "step 51700, training accuracy 0.1\n",
      "step 51800, training accuracy 0.16\n",
      "step 51900, training accuracy 0.18\n",
      "step 52000, training accuracy 0.12\n",
      "step 52100, training accuracy 0.16\n",
      "step 52200, training accuracy 0.18\n",
      "step 52300, training accuracy 0.12\n",
      "step 52400, training accuracy 0.02\n",
      "step 52500, training accuracy 0.08\n",
      "step 52600, training accuracy 0.14\n",
      "step 52700, training accuracy 0.1\n",
      "step 52800, training accuracy 0.14\n",
      "step 52900, training accuracy 0.12\n",
      "step 53000, training accuracy 0.08\n",
      "step 53100, training accuracy 0.04\n",
      "step 53200, training accuracy 0.14\n",
      "step 53300, training accuracy 0.12\n",
      "step 53400, training accuracy 0.14\n",
      "step 53500, training accuracy 0.14\n",
      "step 53600, training accuracy 0.08\n",
      "step 53700, training accuracy 0.14\n",
      "step 53800, training accuracy 0.08\n",
      "step 53900, training accuracy 0.1\n",
      "step 54000, training accuracy 0.06\n",
      "step 54100, training accuracy 0.06\n",
      "step 54200, training accuracy 0.04\n",
      "step 54300, training accuracy 0.12\n",
      "step 54400, training accuracy 0.2\n",
      "step 54500, training accuracy 0.08\n",
      "step 54600, training accuracy 0.22\n",
      "step 54700, training accuracy 0.06\n",
      "step 54800, training accuracy 0.08\n",
      "step 54900, training accuracy 0.12\n",
      "step 55000, training accuracy 0.14\n",
      "step 55100, training accuracy 0.1\n",
      "step 55200, training accuracy 0.08\n",
      "step 55300, training accuracy 0.16\n",
      "step 55400, training accuracy 0.08\n",
      "step 55500, training accuracy 0.18\n",
      "step 55600, training accuracy 0.12\n",
      "step 55700, training accuracy 0.14\n",
      "step 55800, training accuracy 0.14\n",
      "step 55900, training accuracy 0.1\n",
      "step 56000, training accuracy 0.18\n",
      "step 56100, training accuracy 0.14\n",
      "step 56200, training accuracy 0.14\n",
      "step 56300, training accuracy 0.1\n",
      "step 56400, training accuracy 0.06\n",
      "step 56500, training accuracy 0.12\n",
      "step 56600, training accuracy 0.18\n",
      "step 56700, training accuracy 0.14\n",
      "step 56800, training accuracy 0.06\n",
      "step 56900, training accuracy 0.12\n",
      "step 57000, training accuracy 0.08\n",
      "step 57100, training accuracy 0.14\n",
      "step 57200, training accuracy 0.1\n",
      "step 57300, training accuracy 0.16\n",
      "step 57400, training accuracy 0.1\n",
      "step 57500, training accuracy 0.08\n",
      "step 57600, training accuracy 0.1\n",
      "step 57700, training accuracy 0.16\n",
      "step 57800, training accuracy 0.1\n",
      "step 57900, training accuracy 0.1\n",
      "step 58000, training accuracy 0.1\n",
      "step 58100, training accuracy 0.16\n",
      "step 58200, training accuracy 0.08\n",
      "step 58300, training accuracy 0.1\n",
      "step 58400, training accuracy 0.08\n",
      "step 58500, training accuracy 0.08\n",
      "step 58600, training accuracy 0.1\n",
      "step 58700, training accuracy 0.04\n",
      "step 58800, training accuracy 0.12\n",
      "step 58900, training accuracy 0.1\n",
      "step 59000, training accuracy 0.1\n",
      "step 59100, training accuracy 0.06\n",
      "step 59200, training accuracy 0.22\n",
      "step 59300, training accuracy 0.06\n",
      "step 59400, training accuracy 0.02\n",
      "step 59500, training accuracy 0.1\n",
      "step 59600, training accuracy 0.16\n",
      "step 59700, training accuracy 0.1\n",
      "step 59800, training accuracy 0.06\n",
      "step 59900, training accuracy 0.06\n",
      "step 60000, training accuracy 0.04\n",
      "step 60100, training accuracy 0.1\n",
      "step 60200, training accuracy 0.12\n",
      "step 60300, training accuracy 0.12\n",
      "step 60400, training accuracy 0.1\n",
      "step 60500, training accuracy 0.1\n",
      "step 60600, training accuracy 0.14\n",
      "step 60700, training accuracy 0.1\n",
      "step 60800, training accuracy 0.14\n",
      "step 60900, training accuracy 0.1\n",
      "step 61000, training accuracy 0.1\n",
      "step 61100, training accuracy 0.24\n",
      "step 61200, training accuracy 0.1\n",
      "step 61300, training accuracy 0.16\n",
      "step 61400, training accuracy 0.14\n",
      "step 61500, training accuracy 0.08\n",
      "step 61600, training accuracy 0.14\n",
      "step 61700, training accuracy 0.1\n",
      "step 61800, training accuracy 0.1\n",
      "step 61900, training accuracy 0.2\n",
      "step 62000, training accuracy 0.1\n",
      "step 62100, training accuracy 0.16\n",
      "step 62200, training accuracy 0.12\n",
      "step 62300, training accuracy 0.12\n",
      "step 62400, training accuracy 0.1\n",
      "step 62500, training accuracy 0.06\n",
      "step 62600, training accuracy 0.08\n",
      "step 62700, training accuracy 0.1\n",
      "step 62800, training accuracy 0.16\n",
      "step 62900, training accuracy 0.1\n",
      "step 63000, training accuracy 0.06\n",
      "step 63100, training accuracy 0.08\n",
      "step 63200, training accuracy 0.1\n",
      "step 63300, training accuracy 0.06\n",
      "step 63400, training accuracy 0.12\n",
      "step 63500, training accuracy 0.14\n",
      "step 63600, training accuracy 0.12\n",
      "step 63700, training accuracy 0.08\n",
      "step 63800, training accuracy 0.16\n",
      "step 63900, training accuracy 0.04\n",
      "step 64000, training accuracy 0.1\n",
      "step 64100, training accuracy 0.02\n",
      "step 64200, training accuracy 0.08\n",
      "step 64300, training accuracy 0.16\n",
      "step 64400, training accuracy 0.2\n",
      "step 64500, training accuracy 0.1\n",
      "step 64600, training accuracy 0.14\n",
      "step 64700, training accuracy 0.12\n",
      "step 64800, training accuracy 0.1\n",
      "step 64900, training accuracy 0.04\n",
      "step 65000, training accuracy 0.12\n",
      "step 65100, training accuracy 0.1\n",
      "step 65200, training accuracy 0.14\n",
      "step 65300, training accuracy 0.14\n",
      "step 65400, training accuracy 0.08\n",
      "step 65500, training accuracy 0.14\n",
      "step 65600, training accuracy 0.2\n",
      "step 65700, training accuracy 0.14\n",
      "step 65800, training accuracy 0.06\n",
      "step 65900, training accuracy 0.1\n",
      "step 66000, training accuracy 0.14\n",
      "step 66100, training accuracy 0.1\n",
      "step 66200, training accuracy 0.14\n",
      "step 66300, training accuracy 0.16\n",
      "step 66400, training accuracy 0.1\n",
      "step 66500, training accuracy 0.1\n",
      "step 66600, training accuracy 0.12\n",
      "step 66700, training accuracy 0.14\n",
      "step 66800, training accuracy 0.12\n",
      "step 66900, training accuracy 0.18\n",
      "step 67000, training accuracy 0.1\n",
      "step 67100, training accuracy 0.12\n",
      "step 67200, training accuracy 0.12\n",
      "step 67300, training accuracy 0.14\n",
      "step 67400, training accuracy 0.16\n",
      "step 67500, training accuracy 0.14\n",
      "step 67600, training accuracy 0.2\n",
      "step 67700, training accuracy 0.18\n",
      "step 67800, training accuracy 0.08\n",
      "step 67900, training accuracy 0.08\n",
      "step 68000, training accuracy 0.1\n",
      "step 68100, training accuracy 0.08\n",
      "step 68200, training accuracy 0.08\n",
      "step 68300, training accuracy 0.12\n",
      "step 68400, training accuracy 0.04\n",
      "step 68500, training accuracy 0.12\n",
      "step 68600, training accuracy 0.1\n",
      "step 68700, training accuracy 0.14\n",
      "step 68800, training accuracy 0.08\n",
      "step 68900, training accuracy 0.14\n",
      "step 69000, training accuracy 0.06\n",
      "step 69100, training accuracy 0.1\n",
      "step 69200, training accuracy 0.14\n",
      "step 69300, training accuracy 0.08\n",
      "step 69400, training accuracy 0.08\n",
      "step 69500, training accuracy 0.08\n",
      "step 69600, training accuracy 0.06\n",
      "step 69700, training accuracy 0.16\n",
      "step 69800, training accuracy 0.08\n",
      "step 69900, training accuracy 0.02\n",
      "step 70000, training accuracy 0.12\n",
      "step 70100, training accuracy 0.1\n",
      "step 70200, training accuracy 0.12\n",
      "step 70300, training accuracy 0.16\n",
      "step 70400, training accuracy 0.08\n",
      "step 70500, training accuracy 0.16\n",
      "step 70600, training accuracy 0.1\n",
      "step 70700, training accuracy 0.1\n",
      "step 70800, training accuracy 0.08\n",
      "step 70900, training accuracy 0.16\n",
      "step 71000, training accuracy 0.16\n",
      "step 71100, training accuracy 0.1\n",
      "step 71200, training accuracy 0.1\n",
      "step 71300, training accuracy 0.16\n",
      "step 71400, training accuracy 0.08\n",
      "step 71500, training accuracy 0.16\n",
      "step 71600, training accuracy 0.14\n",
      "step 71700, training accuracy 0.1\n",
      "step 71800, training accuracy 0.08\n",
      "step 71900, training accuracy 0.12\n",
      "step 72000, training accuracy 0.18\n",
      "step 72100, training accuracy 0\n",
      "step 72200, training accuracy 0.16\n",
      "step 72300, training accuracy 0.14\n",
      "step 72400, training accuracy 0.08\n",
      "step 72500, training accuracy 0.08\n",
      "step 72600, training accuracy 0.12\n",
      "step 72700, training accuracy 0.12\n",
      "step 72800, training accuracy 0.14\n",
      "step 72900, training accuracy 0.02\n",
      "step 73000, training accuracy 0.06\n",
      "step 73100, training accuracy 0.1\n",
      "step 73200, training accuracy 0.06\n",
      "step 73300, training accuracy 0.1\n",
      "step 73400, training accuracy 0.08\n",
      "step 73500, training accuracy 0.12\n",
      "step 73600, training accuracy 0.1\n",
      "step 73700, training accuracy 0.1\n",
      "step 73800, training accuracy 0.2\n",
      "step 73900, training accuracy 0.08\n",
      "step 74000, training accuracy 0.04\n",
      "step 74100, training accuracy 0.18\n",
      "step 74200, training accuracy 0.06\n",
      "step 74300, training accuracy 0.14\n",
      "step 74400, training accuracy 0.16\n",
      "step 74500, training accuracy 0.04\n",
      "step 74600, training accuracy 0.14\n",
      "step 74700, training accuracy 0.14\n",
      "step 74800, training accuracy 0.14\n",
      "step 74900, training accuracy 0.08\n",
      "step 75000, training accuracy 0.12\n",
      "step 75100, training accuracy 0.1\n",
      "step 75200, training accuracy 0.14\n",
      "step 75300, training accuracy 0.2\n",
      "step 75400, training accuracy 0.08\n",
      "step 75500, training accuracy 0.14\n",
      "step 75600, training accuracy 0.12\n",
      "step 75700, training accuracy 0.08\n",
      "step 75800, training accuracy 0.2\n",
      "step 75900, training accuracy 0.2\n",
      "step 76000, training accuracy 0.08\n",
      "step 76100, training accuracy 0.12\n",
      "step 76200, training accuracy 0.08\n",
      "step 76300, training accuracy 0.12\n",
      "step 76400, training accuracy 0.14\n",
      "step 76500, training accuracy 0.22\n",
      "step 76600, training accuracy 0.08\n",
      "step 76700, training accuracy 0.04\n",
      "step 76800, training accuracy 0.2\n",
      "step 76900, training accuracy 0.12\n",
      "step 77000, training accuracy 0.1\n",
      "step 77100, training accuracy 0.1\n",
      "step 77200, training accuracy 0.16\n",
      "step 77300, training accuracy 0.1\n",
      "step 77400, training accuracy 0.12\n",
      "step 77500, training accuracy 0.22\n",
      "step 77600, training accuracy 0.18\n",
      "step 77700, training accuracy 0.1\n",
      "step 77800, training accuracy 0.12\n",
      "step 77900, training accuracy 0.08\n",
      "step 78000, training accuracy 0.18\n",
      "step 78100, training accuracy 0.08\n",
      "step 78200, training accuracy 0.06\n",
      "step 78300, training accuracy 0.08\n",
      "step 78400, training accuracy 0.16\n",
      "step 78500, training accuracy 0.08\n",
      "step 78600, training accuracy 0.22\n",
      "step 78700, training accuracy 0.12\n",
      "step 78800, training accuracy 0.14\n",
      "step 78900, training accuracy 0.1\n",
      "step 79000, training accuracy 0.18\n",
      "step 79100, training accuracy 0.2\n",
      "step 79200, training accuracy 0.12\n",
      "step 79300, training accuracy 0.1\n",
      "step 79400, training accuracy 0.06\n",
      "step 79500, training accuracy 0.1\n",
      "step 79600, training accuracy 0.08\n",
      "step 79700, training accuracy 0.12\n",
      "step 79800, training accuracy 0.08\n",
      "step 79900, training accuracy 0.08\n",
      "step 80000, training accuracy 0.12\n",
      "step 80100, training accuracy 0.04\n",
      "step 80200, training accuracy 0.06\n",
      "step 80300, training accuracy 0.06\n",
      "step 80400, training accuracy 0.14\n",
      "step 80500, training accuracy 0.12\n",
      "step 80600, training accuracy 0.16\n",
      "step 80700, training accuracy 0.02\n",
      "step 80800, training accuracy 0.16\n",
      "step 80900, training accuracy 0.08\n",
      "step 81000, training accuracy 0.14\n",
      "step 81100, training accuracy 0.18\n",
      "step 81200, training accuracy 0.08\n",
      "step 81300, training accuracy 0.14\n",
      "step 81400, training accuracy 0.06\n",
      "step 81500, training accuracy 0.08\n",
      "step 81600, training accuracy 0.16\n",
      "step 81700, training accuracy 0.12\n",
      "step 81800, training accuracy 0.18\n",
      "step 81900, training accuracy 0.06\n",
      "step 82000, training accuracy 0.1\n",
      "step 82100, training accuracy 0.06\n",
      "step 82200, training accuracy 0.1\n",
      "step 82300, training accuracy 0.16\n",
      "step 82400, training accuracy 0.2\n",
      "step 82500, training accuracy 0.2\n",
      "step 82600, training accuracy 0.14\n",
      "step 82700, training accuracy 0.1\n",
      "step 82800, training accuracy 0.08\n",
      "step 82900, training accuracy 0.1\n",
      "step 83000, training accuracy 0.16\n",
      "step 83100, training accuracy 0.06\n",
      "step 83200, training accuracy 0.12\n",
      "step 83300, training accuracy 0.12\n",
      "step 83400, training accuracy 0\n",
      "step 83500, training accuracy 0.14\n",
      "step 83600, training accuracy 0.08\n",
      "step 83700, training accuracy 0.18\n",
      "step 83800, training accuracy 0.12\n",
      "step 83900, training accuracy 0.14\n",
      "step 84000, training accuracy 0.08\n",
      "step 84100, training accuracy 0.14\n",
      "step 84200, training accuracy 0.1\n",
      "step 84300, training accuracy 0.08\n",
      "step 84400, training accuracy 0.1\n",
      "step 84500, training accuracy 0.16\n",
      "step 84600, training accuracy 0.1\n",
      "step 84700, training accuracy 0.12\n",
      "step 84800, training accuracy 0.14\n",
      "step 84900, training accuracy 0.06\n",
      "step 85000, training accuracy 0.12\n",
      "step 85100, training accuracy 0.1\n",
      "step 85200, training accuracy 0.12\n",
      "step 85300, training accuracy 0.1\n",
      "step 85400, training accuracy 0.06\n",
      "step 85500, training accuracy 0.14\n",
      "step 85600, training accuracy 0.1\n",
      "step 85700, training accuracy 0.1\n",
      "step 85800, training accuracy 0.06\n",
      "step 85900, training accuracy 0.16\n",
      "step 86000, training accuracy 0.08\n",
      "step 86100, training accuracy 0.16\n",
      "step 86200, training accuracy 0.08\n",
      "step 86300, training accuracy 0.16\n",
      "step 86400, training accuracy 0.08\n",
      "step 86500, training accuracy 0.14\n",
      "step 86600, training accuracy 0.14\n",
      "step 86700, training accuracy 0.1\n",
      "step 86800, training accuracy 0.04\n",
      "step 86900, training accuracy 0.08\n",
      "step 87000, training accuracy 0.08\n",
      "step 87100, training accuracy 0.14\n",
      "step 87200, training accuracy 0.14\n",
      "step 87300, training accuracy 0.08\n",
      "step 87400, training accuracy 0.1\n",
      "step 87500, training accuracy 0.16\n",
      "step 87600, training accuracy 0.12\n",
      "step 87700, training accuracy 0.14\n",
      "step 87800, training accuracy 0.08\n",
      "step 87900, training accuracy 0.16\n",
      "step 88000, training accuracy 0.12\n",
      "step 88100, training accuracy 0.14\n",
      "step 88200, training accuracy 0.12\n",
      "step 88300, training accuracy 0.14\n",
      "step 88400, training accuracy 0.16\n",
      "step 88500, training accuracy 0.12\n",
      "step 88600, training accuracy 0.12\n",
      "step 88700, training accuracy 0.16\n",
      "step 88800, training accuracy 0.1\n",
      "step 88900, training accuracy 0.24\n",
      "step 89000, training accuracy 0.2\n",
      "step 89100, training accuracy 0.1\n",
      "step 89200, training accuracy 0.12\n",
      "step 89300, training accuracy 0.16\n",
      "step 89400, training accuracy 0.04\n",
      "step 89500, training accuracy 0.12\n",
      "step 89600, training accuracy 0.12\n",
      "step 89700, training accuracy 0.1\n",
      "step 89800, training accuracy 0.08\n",
      "step 89900, training accuracy 0.04\n",
      "step 90000, training accuracy 0.1\n",
      "step 90100, training accuracy 0.06\n",
      "step 90200, training accuracy 0.14\n",
      "step 90300, training accuracy 0.14\n",
      "step 90400, training accuracy 0.1\n",
      "step 90500, training accuracy 0.12\n",
      "step 90600, training accuracy 0.1\n",
      "step 90700, training accuracy 0.12\n",
      "step 90800, training accuracy 0.2\n",
      "step 90900, training accuracy 0.1\n",
      "step 91000, training accuracy 0.04\n",
      "step 91100, training accuracy 0.16\n",
      "step 91200, training accuracy 0.1\n",
      "step 91300, training accuracy 0.16\n",
      "step 91400, training accuracy 0\n",
      "step 91500, training accuracy 0.1\n",
      "step 91600, training accuracy 0.08\n",
      "step 91700, training accuracy 0.06\n",
      "step 91800, training accuracy 0.14\n",
      "step 91900, training accuracy 0.08\n",
      "step 92000, training accuracy 0.14\n",
      "step 92100, training accuracy 0.12\n",
      "step 92200, training accuracy 0.16\n",
      "step 92300, training accuracy 0.08\n",
      "step 92400, training accuracy 0.1\n",
      "step 92500, training accuracy 0.06\n",
      "step 92600, training accuracy 0.18\n",
      "step 92700, training accuracy 0.06\n",
      "step 92800, training accuracy 0.12\n",
      "step 92900, training accuracy 0.16\n",
      "step 93000, training accuracy 0.1\n",
      "step 93100, training accuracy 0.14\n",
      "step 93200, training accuracy 0.08\n",
      "step 93300, training accuracy 0.16\n",
      "step 93400, training accuracy 0.14\n",
      "step 93500, training accuracy 0.04\n",
      "step 93600, training accuracy 0.22\n",
      "step 93700, training accuracy 0.1\n",
      "step 93800, training accuracy 0.12\n",
      "step 93900, training accuracy 0.16\n",
      "step 94000, training accuracy 0.08\n",
      "step 94100, training accuracy 0.06\n",
      "step 94200, training accuracy 0.04\n",
      "step 94300, training accuracy 0.08\n",
      "step 94400, training accuracy 0.08\n",
      "step 94500, training accuracy 0.14\n",
      "step 94600, training accuracy 0.24\n",
      "step 94700, training accuracy 0.08\n",
      "step 94800, training accuracy 0.14\n",
      "step 94900, training accuracy 0.02\n",
      "step 95000, training accuracy 0.12\n",
      "step 95100, training accuracy 0.14\n",
      "step 95200, training accuracy 0.1\n",
      "step 95300, training accuracy 0.1\n",
      "step 95400, training accuracy 0.16\n",
      "step 95500, training accuracy 0.06\n",
      "step 95600, training accuracy 0.16\n",
      "step 95700, training accuracy 0.18\n",
      "step 95800, training accuracy 0.08\n",
      "step 95900, training accuracy 0.12\n",
      "step 96000, training accuracy 0.16\n",
      "step 96100, training accuracy 0.06\n",
      "step 96200, training accuracy 0.08\n",
      "step 96300, training accuracy 0.16\n",
      "step 96400, training accuracy 0.12\n",
      "step 96500, training accuracy 0.1\n",
      "step 96600, training accuracy 0.12\n",
      "step 96700, training accuracy 0.14\n",
      "step 96800, training accuracy 0.18\n",
      "step 96900, training accuracy 0.04\n",
      "step 97000, training accuracy 0.16\n",
      "step 97100, training accuracy 0.14\n",
      "step 97200, training accuracy 0.1\n",
      "step 97300, training accuracy 0.06\n",
      "step 97400, training accuracy 0.14\n",
      "step 97500, training accuracy 0.16\n",
      "step 97600, training accuracy 0.06\n",
      "step 97700, training accuracy 0.02\n",
      "step 97800, training accuracy 0.18\n",
      "step 97900, training accuracy 0.16\n",
      "step 98000, training accuracy 0.16\n",
      "step 98100, training accuracy 0.14\n",
      "step 98200, training accuracy 0.06\n",
      "step 98300, training accuracy 0.08\n",
      "step 98400, training accuracy 0.14\n",
      "step 98500, training accuracy 0.1\n",
      "step 98600, training accuracy 0.12\n",
      "step 98700, training accuracy 0.1\n",
      "step 98800, training accuracy 0.12\n",
      "step 98900, training accuracy 0.2\n",
      "step 99000, training accuracy 0.08\n",
      "step 99100, training accuracy 0.24\n",
      "step 99200, training accuracy 0.1\n",
      "step 99300, training accuracy 0.1\n",
      "step 99400, training accuracy 0.1\n",
      "step 99500, training accuracy 0.06\n",
      "step 99600, training accuracy 0.08\n",
      "step 99700, training accuracy 0.16\n",
      "step 99800, training accuracy 0.14\n",
      "step 99900, training accuracy 0.12\n",
      "step 100000, training accuracy 0.22\n",
      "step 100100, training accuracy 0.1\n",
      "step 100200, training accuracy 0.08\n",
      "step 100300, training accuracy 0.16\n",
      "step 100400, training accuracy 0.1\n",
      "step 100500, training accuracy 0.12\n",
      "step 100600, training accuracy 0.08\n",
      "step 100700, training accuracy 0.08\n",
      "step 100800, training accuracy 0.1\n",
      "step 100900, training accuracy 0.1\n",
      "step 101000, training accuracy 0.16\n",
      "step 101100, training accuracy 0.14\n",
      "step 101200, training accuracy 0.1\n",
      "step 101300, training accuracy 0.06\n",
      "step 101400, training accuracy 0.1\n",
      "step 101500, training accuracy 0.16\n",
      "step 101600, training accuracy 0.12\n",
      "step 101700, training accuracy 0.08\n",
      "step 101800, training accuracy 0.12\n",
      "step 101900, training accuracy 0.08\n",
      "step 102000, training accuracy 0.12\n",
      "step 102100, training accuracy 0.1\n",
      "step 102200, training accuracy 0.12\n",
      "step 102300, training accuracy 0.12\n",
      "step 102400, training accuracy 0.08\n",
      "step 102500, training accuracy 0.14\n",
      "step 102600, training accuracy 0.06\n",
      "step 102700, training accuracy 0.1\n",
      "step 102800, training accuracy 0.12\n",
      "step 102900, training accuracy 0.14\n",
      "step 103000, training accuracy 0.08\n",
      "step 103100, training accuracy 0.02\n",
      "step 103200, training accuracy 0.08\n",
      "step 103300, training accuracy 0.18\n",
      "step 103400, training accuracy 0.14\n",
      "step 103500, training accuracy 0.16\n",
      "step 103600, training accuracy 0.16\n",
      "step 103700, training accuracy 0.14\n",
      "step 103800, training accuracy 0.14\n",
      "step 103900, training accuracy 0.18\n",
      "step 104000, training accuracy 0.12\n",
      "step 104100, training accuracy 0.08\n",
      "step 104200, training accuracy 0.1\n",
      "step 104300, training accuracy 0.16\n",
      "step 104400, training accuracy 0.06\n",
      "step 104500, training accuracy 0.14\n",
      "step 104600, training accuracy 0.06\n",
      "step 104700, training accuracy 0.1\n",
      "step 104800, training accuracy 0.12\n",
      "step 104900, training accuracy 0.08\n",
      "step 105000, training accuracy 0.18\n",
      "step 105100, training accuracy 0.06\n",
      "step 105200, training accuracy 0.06\n",
      "step 105300, training accuracy 0.16\n",
      "step 105400, training accuracy 0.08\n",
      "step 105500, training accuracy 0.08\n",
      "step 105600, training accuracy 0.12\n",
      "step 105700, training accuracy 0.08\n",
      "step 105800, training accuracy 0.06\n",
      "step 105900, training accuracy 0\n",
      "step 106000, training accuracy 0.12\n",
      "step 106100, training accuracy 0.14\n",
      "step 106200, training accuracy 0.14\n",
      "step 106300, training accuracy 0.16\n",
      "step 106400, training accuracy 0.06\n",
      "step 106500, training accuracy 0.1\n",
      "step 106600, training accuracy 0.18\n",
      "step 106700, training accuracy 0.14\n",
      "step 106800, training accuracy 0.14\n",
      "step 106900, training accuracy 0.1\n",
      "step 107000, training accuracy 0.18\n",
      "step 107100, training accuracy 0.04\n",
      "step 107200, training accuracy 0.12\n",
      "step 107300, training accuracy 0.12\n",
      "step 107400, training accuracy 0.06\n",
      "step 107500, training accuracy 0.16\n",
      "step 107600, training accuracy 0.1\n",
      "step 107700, training accuracy 0.12\n",
      "step 107800, training accuracy 0.12\n",
      "step 107900, training accuracy 0.16\n",
      "step 108000, training accuracy 0.16\n",
      "step 108100, training accuracy 0.12\n",
      "step 108200, training accuracy 0.16\n",
      "step 108300, training accuracy 0.12\n",
      "step 108400, training accuracy 0.12\n",
      "step 108500, training accuracy 0.14\n",
      "step 108600, training accuracy 0.06\n",
      "step 108700, training accuracy 0.06\n",
      "step 108800, training accuracy 0.08\n",
      "step 108900, training accuracy 0.16\n",
      "step 109000, training accuracy 0.08\n",
      "step 109100, training accuracy 0.16\n",
      "step 109200, training accuracy 0.04\n",
      "step 109300, training accuracy 0.08\n",
      "step 109400, training accuracy 0.1\n",
      "step 109500, training accuracy 0.12\n",
      "step 109600, training accuracy 0.08\n",
      "step 109700, training accuracy 0.14\n",
      "step 109800, training accuracy 0.04\n",
      "step 109900, training accuracy 0.14\n",
      "step 110000, training accuracy 0.14\n",
      "step 110100, training accuracy 0.2\n",
      "step 110200, training accuracy 0.08\n",
      "step 110300, training accuracy 0.14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b7cd4bbc50c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step %d, training accuracy %g\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;31m#   summary, _, outshape, wc111, bc111, yop, yr, yopv, yc, hp1, hp2 = sess.run([merged_summary_op,train_step,out_shape, W_conv1, b_conv1, y_outer_product, y_raw, y_outer_product_vec, y_conv, h_pool1, h_pool2], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m   \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwc111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged_summary_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_conv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_conv1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_pool1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;31m#   print(\"out shape\", outshape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.name_scope('Wx_B') as scope:\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_batch_size = tf.shape(x)[0]\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32], name='W_conv1')\n",
    "    b_conv1 = bias_variable([32], name='b_conv1')\n",
    "\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "#     h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 5, 5, 1, 32) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    W_conv2 = weight_variable([5, 5, 32, 32], name='W_conv2')\n",
    "    b_conv2 = bias_variable([32], name='b_conv2')\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "#     h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, 5, 5, 32, 64) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    W_fc1 = weight_variable([7 * 7 * 32, 20], name='W_fc1')\n",
    "    b_fc1 = bias_variable([20], name='b_fc1')\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*32])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    y_raw = h_fc1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#  set up saver\n",
    "saver = tf.train.Saver({\"Wx_B/W_conv1\": W_conv1, \"Wx_B/b_conv1\": b_conv1, \"Wx_B/W_conv2\": W_conv2, \"Wx_B/b_conv2\": b_conv2,\n",
    "                       \"Wx_B/W_fc1\": W_fc1, \"Wx_B/b_fc1\": b_fc1,})\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "saver.restore(sess, \"/tmp/model2.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "#  FINE BEFORE HERE\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('Wx_B') as scope:\n",
    "\n",
    "\n",
    "        \n",
    "    def batch_outer_product(x, y):\n",
    "#         print x.get_shape()  # ==> [U, N]\n",
    "#         print y.get_shape()  # ==> [N, V]\n",
    "        print(\"it begins\")\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         x_transposed = tf.transpose(x)\n",
    "        x_transposed = x\n",
    "#         print x_transposed.get_shape()  # ==> [N, U]\n",
    "\n",
    "        x_transposed_as_matrix_batch = tf.expand_dims(x_transposed, 2)\n",
    "        print(x_transposed_as_matrix_batch.shape)\n",
    "#         print x_transposed_as_matrix_batch.get_shape()  # ==> [N, U, 1]\n",
    "\n",
    "        y_as_matrix_batch = tf.expand_dims(y, 1)\n",
    "        print(y_as_matrix_batch.shape)\n",
    "\n",
    "#         print y_as_matrix_batch.get_shape()  # ==> [N, 1, V]\n",
    "\n",
    "        result = tf.matmul(x_transposed_as_matrix_batch, y_as_matrix_batch)\n",
    "    \n",
    "#         outer_products = []\n",
    "#         N, H = tf.shape(x)[0], tf.shape(x)[1]\n",
    "#         W = tf.shape(y)[1]\n",
    "#         for i in tf.range(x_batch_size):\n",
    "#             outer_products.append(tf.matmul(x_transposed_as_matrix_batch[i], y_as_matrix_batch[i]))\n",
    "    \n",
    "#         result = tf.reshape(tf.pack(outer_products), shape=(N, H, W))\n",
    "    \n",
    "        print(result.shape)\n",
    "#         result = tf.batch_matmul(x_transposed_as_matrix_batch, y_as_matrix_batch)\n",
    "    #         print result.get_shape()  # ==> [N, U, V]\n",
    "        print(\"It ends\")\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    #  shape 50 x 10, to 50 x 100\n",
    "    print(y_raw.shape)\n",
    "    y_outer_product = batch_outer_product(y_raw, y_raw)\n",
    "    print(y_outer_product.shape)\n",
    "\n",
    "    \n",
    "#     #  shape = 50 x 100\n",
    "    y_outer_product_vec = tf.reshape(y_outer_product, [x_batch_size,-1])\n",
    "    y_outer_product_norm = tf.nn.relu(tf.sign(y_outer_product_vec) * tf.sqrt(tf.abs(y_outer_product_vec)))\n",
    "    print(y_outer_product_norm.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #  final fc layer transformation to 10 classes\n",
    "#     W_fc3 = weight_variable([100, 10])\n",
    "    W_fc3 = weight_variable([400, 10])\n",
    "    b_fc3 = bias_variable([10])\n",
    "    y_fc3 = tf.matmul(y_outer_product_norm, W_fc3) + b_fc3\n",
    "#     y_fc3 = tf.matmul(h_fc1, W_fc3) + b_fc3\n",
    "\n",
    "    \n",
    "    y_conv=tf.nn.softmax(y_fc3)\n",
    "    out_shape = tf.shape(y_conv)\n",
    "    print(y_conv.shape)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#  FINE AFTER HERE\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def l2_loss(tensor_inst):\n",
    "    return tf.reduce_sum(tensor_inst ** 2)\n",
    "beta = 0.0001\n",
    "\n",
    "with tf.name_scope('cost') as scope:\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1])) + \\\n",
    "                beta*l2_loss(W_conv1) +\\\n",
    "                beta*l2_loss(W_conv2) +\\\n",
    "                beta*l2_loss(b_conv1) +\\\n",
    "                beta*l2_loss(b_conv2) +\\\n",
    "                beta*l2_loss(W_fc1) +\\\n",
    "                beta*l2_loss(b_fc1) +\\\n",
    "                beta*l2_loss(W_fc3) +\\\n",
    "                beta*l2_loss(b_fc3)\n",
    "#                 beta*l2_loss(W_fc2) +\\\n",
    "#                 beta*l2_loss(b_fc2) +\\\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('optimizer') as scope:\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope('accuracy') as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  summary writers for debugging\n",
    "summary_writer = tf.summary.FileWriter( '/home/tuna/Projects/CS678/Deep_Learning_Project_2/tf_logs/4_layers_test_15_outer_product_load_after_tested', graph=sess.graph )\n",
    "acc_summary = tf.summary.scalar( 'accuracy', accuracy )\n",
    "loss_summary = tf.summary.scalar( 'loss', cross_entropy )\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(150000000):\n",
    "  batch = mnist.train.next_batch(batch_size)\n",
    "#   print(\"Batch\", i)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "#   summary, _, outshape, wc111, bc111, yop, yr, yopv, yc, hp1, hp2 = sess.run([merged_summary_op,train_step,out_shape, W_conv1, b_conv1, y_outer_product, y_raw, y_outer_product_vec, y_conv, h_pool1, h_pool2], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "  summary, _, outshape, wc111, bc111, yc, hp1 = sess.run([merged_summary_op,train_step,out_shape, W_conv1, b_conv1,  y_conv, h_pool1], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "  summary_writer.add_summary(summary, i)\n",
    "#   print(\"out shape\", outshape)\n",
    "#   print(\"wc1\", wc111)\n",
    "#   print(\"bc1\", bc111)\n",
    "#   print(\"hp1\", hp1)\n",
    "#   print(\"hp2\", hp2)\n",
    "#   print(\"yr\", yr)\n",
    "#   print(\"yop\", yop)\n",
    "#   print(\"yopv\", yopv)\n",
    "#   print(\"y_softmax\", yc)\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "\n",
    "summary_writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20)\n",
      "it begins\n",
      "(?, 20)\n",
      "(?, 20)\n",
      "(?, 20, 1)\n",
      "(?, 1, 20)\n",
      "(?, 20, 20)\n",
      "It ends\n",
      "(?, 20, 20)\n",
      "(?, ?)\n",
      "(?, 10)\n",
      "step 0, training accuracy 0.04\n",
      "step 100, training accuracy 0.12\n",
      "step 200, training accuracy 0.16\n",
      "step 300, training accuracy 0.14\n",
      "step 400, training accuracy 0.12\n",
      "step 500, training accuracy 0.1\n",
      "step 600, training accuracy 0.12\n",
      "step 700, training accuracy 0.12\n",
      "step 800, training accuracy 0.12\n",
      "step 900, training accuracy 0.06\n",
      "step 1000, training accuracy 0.12\n",
      "step 1100, training accuracy 0.08\n",
      "step 1200, training accuracy 0.08\n",
      "step 1300, training accuracy 0.1\n",
      "step 1400, training accuracy 0.08\n",
      "step 1500, training accuracy 0.06\n",
      "step 1600, training accuracy 0.12\n",
      "step 1700, training accuracy 0.1\n",
      "step 1800, training accuracy 0.14\n",
      "step 1900, training accuracy 0.06\n",
      "step 2000, training accuracy 0.1\n",
      "step 2100, training accuracy 0.12\n",
      "step 2200, training accuracy 0.12\n",
      "step 2300, training accuracy 0.1\n",
      "step 2400, training accuracy 0.1\n",
      "step 2500, training accuracy 0.1\n",
      "step 2600, training accuracy 0.1\n",
      "step 2700, training accuracy 0.22\n",
      "step 2800, training accuracy 0\n",
      "step 2900, training accuracy 0.12\n",
      "step 3000, training accuracy 0.06\n",
      "step 3100, training accuracy 0.08\n",
      "step 3200, training accuracy 0.08\n",
      "step 3300, training accuracy 0.08\n",
      "step 3400, training accuracy 0.1\n",
      "step 3500, training accuracy 0.08\n",
      "step 3600, training accuracy 0.1\n",
      "step 3700, training accuracy 0.18\n",
      "step 3800, training accuracy 0.16\n",
      "step 3900, training accuracy 0.08\n",
      "step 4000, training accuracy 0.14\n",
      "step 4100, training accuracy 0.14\n",
      "step 4200, training accuracy 0.2\n",
      "step 4300, training accuracy 0.02\n",
      "step 4400, training accuracy 0.08\n",
      "step 4500, training accuracy 0.04\n",
      "step 4600, training accuracy 0.04\n",
      "step 4700, training accuracy 0.16\n",
      "step 4800, training accuracy 0.12\n",
      "step 4900, training accuracy 0.06\n",
      "step 5000, training accuracy 0.08\n",
      "step 5100, training accuracy 0.1\n",
      "step 5200, training accuracy 0.14\n",
      "step 5300, training accuracy 0.16\n",
      "step 5400, training accuracy 0.1\n",
      "step 5500, training accuracy 0.18\n",
      "step 5600, training accuracy 0.12\n",
      "step 5700, training accuracy 0.16\n",
      "step 5800, training accuracy 0.22\n",
      "step 5900, training accuracy 0.16\n",
      "step 6000, training accuracy 0.14\n",
      "step 6100, training accuracy 0.18\n",
      "step 6200, training accuracy 0.12\n",
      "step 6300, training accuracy 0.16\n",
      "step 6400, training accuracy 0.12\n",
      "step 6500, training accuracy 0.18\n",
      "step 6600, training accuracy 0.12\n",
      "step 6700, training accuracy 0.12\n",
      "step 6800, training accuracy 0.12\n",
      "step 6900, training accuracy 0.12\n",
      "step 7000, training accuracy 0.12\n",
      "step 7100, training accuracy 0.06\n",
      "step 7200, training accuracy 0.18\n",
      "step 7300, training accuracy 0.12\n",
      "step 7400, training accuracy 0.1\n",
      "step 7500, training accuracy 0.06\n",
      "step 7600, training accuracy 0.14\n",
      "step 7700, training accuracy 0.1\n",
      "step 7800, training accuracy 0.08\n",
      "step 7900, training accuracy 0.16\n",
      "step 8000, training accuracy 0.08\n",
      "step 8100, training accuracy 0.18\n",
      "step 8200, training accuracy 0.14\n",
      "step 8300, training accuracy 0.2\n",
      "step 8400, training accuracy 0.1\n",
      "step 8500, training accuracy 0.12\n",
      "step 8600, training accuracy 0.12\n",
      "step 8700, training accuracy 0.2\n",
      "step 8800, training accuracy 0.08\n",
      "step 8900, training accuracy 0.12\n",
      "step 9000, training accuracy 0.14\n",
      "step 9100, training accuracy 0.12\n",
      "step 9200, training accuracy 0.02\n",
      "step 9300, training accuracy 0.12\n",
      "step 9400, training accuracy 0.06\n",
      "step 9500, training accuracy 0.1\n",
      "step 9600, training accuracy 0.04\n",
      "step 9700, training accuracy 0.2\n",
      "step 9800, training accuracy 0.18\n",
      "step 9900, training accuracy 0.12\n",
      "step 10000, training accuracy 0.12\n",
      "step 10100, training accuracy 0.1\n",
      "step 10200, training accuracy 0.1\n",
      "step 10300, training accuracy 0.02\n",
      "step 10400, training accuracy 0.06\n",
      "step 10500, training accuracy 0.14\n",
      "step 10600, training accuracy 0.08\n",
      "step 10700, training accuracy 0.2\n",
      "step 10800, training accuracy 0.18\n",
      "step 10900, training accuracy 0.06\n",
      "step 11000, training accuracy 0.1\n",
      "step 11100, training accuracy 0.06\n",
      "step 11200, training accuracy 0.12\n",
      "step 11300, training accuracy 0.06\n",
      "step 11400, training accuracy 0.12\n",
      "step 11500, training accuracy 0.1\n",
      "step 11600, training accuracy 0.18\n",
      "step 11700, training accuracy 0.1\n",
      "step 11800, training accuracy 0.08\n",
      "step 11900, training accuracy 0.08\n",
      "step 12000, training accuracy 0.08\n",
      "step 12100, training accuracy 0.08\n",
      "step 12200, training accuracy 0.14\n",
      "step 12300, training accuracy 0.22\n",
      "step 12400, training accuracy 0.08\n",
      "step 12500, training accuracy 0.12\n",
      "step 12600, training accuracy 0.08\n",
      "step 12700, training accuracy 0.12\n",
      "step 12800, training accuracy 0.18\n",
      "step 12900, training accuracy 0.1\n",
      "step 13000, training accuracy 0.04\n",
      "step 13100, training accuracy 0.12\n",
      "step 13200, training accuracy 0.08\n",
      "step 13300, training accuracy 0.06\n",
      "step 13400, training accuracy 0.06\n",
      "step 13500, training accuracy 0.04\n",
      "step 13600, training accuracy 0.1\n",
      "step 13700, training accuracy 0.14\n",
      "step 13800, training accuracy 0.04\n",
      "step 13900, training accuracy 0.12\n",
      "step 14000, training accuracy 0.12\n",
      "step 14100, training accuracy 0.12\n",
      "step 14200, training accuracy 0.16\n",
      "step 14300, training accuracy 0.08\n",
      "step 14400, training accuracy 0.12\n",
      "step 14500, training accuracy 0.14\n",
      "step 14600, training accuracy 0\n",
      "step 14700, training accuracy 0.1\n",
      "step 14800, training accuracy 0.06\n",
      "step 14900, training accuracy 0.1\n",
      "step 15000, training accuracy 0.12\n",
      "step 15100, training accuracy 0.1\n",
      "step 15200, training accuracy 0.1\n",
      "step 15300, training accuracy 0.06\n",
      "step 15400, training accuracy 0.18\n",
      "step 15500, training accuracy 0.1\n",
      "step 15600, training accuracy 0.12\n",
      "step 15700, training accuracy 0.16\n",
      "step 15800, training accuracy 0.02\n",
      "step 15900, training accuracy 0.16\n",
      "step 16000, training accuracy 0.1\n",
      "step 16100, training accuracy 0.04\n",
      "step 16200, training accuracy 0.04\n",
      "step 16300, training accuracy 0.14\n",
      "step 16400, training accuracy 0\n",
      "step 16500, training accuracy 0.1\n",
      "step 16600, training accuracy 0.1\n",
      "step 16700, training accuracy 0.14\n",
      "step 16800, training accuracy 0.08\n",
      "step 16900, training accuracy 0.16\n",
      "step 17000, training accuracy 0.14\n",
      "step 17100, training accuracy 0.1\n",
      "step 17200, training accuracy 0.12\n",
      "step 17300, training accuracy 0.06\n",
      "step 17400, training accuracy 0.08\n",
      "step 17500, training accuracy 0.12\n",
      "step 17600, training accuracy 0.12\n",
      "step 17700, training accuracy 0.12\n",
      "step 17800, training accuracy 0.14\n",
      "step 17900, training accuracy 0.06\n",
      "step 18000, training accuracy 0.14\n",
      "step 18100, training accuracy 0.16\n",
      "step 18200, training accuracy 0.1\n",
      "step 18300, training accuracy 0.12\n",
      "step 18400, training accuracy 0.06\n",
      "step 18500, training accuracy 0.08\n",
      "step 18600, training accuracy 0.12\n",
      "step 18700, training accuracy 0.08\n",
      "step 18800, training accuracy 0.1\n",
      "step 18900, training accuracy 0.24\n",
      "step 19000, training accuracy 0.1\n",
      "step 19100, training accuracy 0.14\n",
      "step 19200, training accuracy 0.06\n",
      "step 19300, training accuracy 0.16\n",
      "step 19400, training accuracy 0.12\n",
      "step 19500, training accuracy 0.12\n",
      "step 19600, training accuracy 0.24\n",
      "step 19700, training accuracy 0.08\n",
      "step 19800, training accuracy 0.08\n",
      "step 19900, training accuracy 0.12\n",
      "step 20000, training accuracy 0.1\n",
      "step 20100, training accuracy 0.04\n",
      "step 20200, training accuracy 0.1\n",
      "step 20300, training accuracy 0.08\n",
      "step 20400, training accuracy 0.16\n",
      "step 20500, training accuracy 0.12\n",
      "step 20600, training accuracy 0.14\n",
      "step 20700, training accuracy 0.12\n",
      "step 20800, training accuracy 0.12\n",
      "step 20900, training accuracy 0.1\n",
      "step 21000, training accuracy 0.16\n",
      "step 21100, training accuracy 0.16\n",
      "step 21200, training accuracy 0.16\n",
      "step 21300, training accuracy 0.2\n",
      "step 21400, training accuracy 0.12\n",
      "step 21500, training accuracy 0.1\n",
      "step 21600, training accuracy 0.2\n",
      "step 21700, training accuracy 0.04\n",
      "step 21800, training accuracy 0.18\n",
      "step 21900, training accuracy 0.12\n",
      "step 22000, training accuracy 0.04\n",
      "step 22100, training accuracy 0.08\n",
      "step 22200, training accuracy 0.1\n",
      "step 22300, training accuracy 0.12\n",
      "step 22400, training accuracy 0.22\n",
      "step 22500, training accuracy 0\n",
      "step 22600, training accuracy 0.08\n",
      "step 22700, training accuracy 0.1\n",
      "step 22800, training accuracy 0.12\n",
      "step 22900, training accuracy 0.06\n",
      "step 23000, training accuracy 0.12\n",
      "step 23100, training accuracy 0.18\n",
      "step 23200, training accuracy 0.04\n",
      "step 23300, training accuracy 0.02\n",
      "step 23400, training accuracy 0.18\n",
      "step 23500, training accuracy 0.18\n",
      "step 23600, training accuracy 0.08\n",
      "step 23700, training accuracy 0.08\n",
      "step 23800, training accuracy 0.08\n",
      "step 23900, training accuracy 0.14\n",
      "step 24000, training accuracy 0.14\n",
      "step 24100, training accuracy 0.12\n",
      "step 24200, training accuracy 0.12\n",
      "step 24300, training accuracy 0.12\n",
      "step 24400, training accuracy 0.18\n",
      "step 24500, training accuracy 0.1\n",
      "step 24600, training accuracy 0.1\n",
      "step 24700, training accuracy 0.12\n",
      "step 24800, training accuracy 0.12\n",
      "step 24900, training accuracy 0.2\n",
      "step 25000, training accuracy 0.12\n",
      "step 25100, training accuracy 0.1\n",
      "step 25200, training accuracy 0.14\n",
      "step 25300, training accuracy 0.06\n",
      "step 25400, training accuracy 0.12\n",
      "step 25500, training accuracy 0.12\n",
      "step 25600, training accuracy 0.04\n",
      "step 25700, training accuracy 0.08\n",
      "step 25800, training accuracy 0.06\n",
      "step 25900, training accuracy 0.04\n",
      "step 26000, training accuracy 0.08\n",
      "step 26100, training accuracy 0.08\n",
      "step 26200, training accuracy 0.12\n",
      "step 26300, training accuracy 0.1\n",
      "step 26400, training accuracy 0.18\n",
      "step 26500, training accuracy 0.1\n",
      "step 26600, training accuracy 0.1\n",
      "step 26700, training accuracy 0.04\n",
      "step 26800, training accuracy 0.08\n",
      "step 26900, training accuracy 0.12\n",
      "step 27000, training accuracy 0.1\n",
      "step 27100, training accuracy 0.12\n",
      "step 27200, training accuracy 0.1\n",
      "step 27300, training accuracy 0.06\n",
      "step 27400, training accuracy 0.16\n",
      "step 27500, training accuracy 0.14\n",
      "step 27600, training accuracy 0.08\n",
      "step 27700, training accuracy 0.1\n",
      "step 27800, training accuracy 0.1\n",
      "step 27900, training accuracy 0.06\n",
      "step 28000, training accuracy 0.12\n",
      "step 28100, training accuracy 0.08\n",
      "step 28200, training accuracy 0.14\n",
      "step 28300, training accuracy 0.12\n",
      "step 28400, training accuracy 0.1\n",
      "step 28500, training accuracy 0.18\n",
      "step 28600, training accuracy 0.04\n",
      "step 28700, training accuracy 0.12\n",
      "step 28800, training accuracy 0.08\n",
      "step 28900, training accuracy 0.1\n",
      "step 29000, training accuracy 0.04\n",
      "step 29100, training accuracy 0.12\n",
      "step 29200, training accuracy 0.14\n",
      "step 29300, training accuracy 0.2\n",
      "step 29400, training accuracy 0.16\n",
      "step 29500, training accuracy 0.06\n",
      "step 29600, training accuracy 0.12\n",
      "step 29700, training accuracy 0.16\n",
      "step 29800, training accuracy 0.12\n",
      "step 29900, training accuracy 0.12\n",
      "step 30000, training accuracy 0.2\n",
      "step 30100, training accuracy 0.08\n",
      "step 30200, training accuracy 0.2\n",
      "step 30300, training accuracy 0.12\n",
      "step 30400, training accuracy 0.12\n",
      "step 30500, training accuracy 0.16\n",
      "step 30600, training accuracy 0.08\n",
      "step 30700, training accuracy 0.04\n",
      "step 30800, training accuracy 0.04\n",
      "step 30900, training accuracy 0.14\n",
      "step 31000, training accuracy 0.1\n",
      "step 31100, training accuracy 0.08\n",
      "step 31200, training accuracy 0.1\n",
      "step 31300, training accuracy 0.06\n",
      "step 31400, training accuracy 0.1\n",
      "step 31500, training accuracy 0.06\n",
      "step 31600, training accuracy 0.16\n",
      "step 31700, training accuracy 0.1\n",
      "step 31800, training accuracy 0.08\n",
      "step 31900, training accuracy 0.08\n",
      "step 32000, training accuracy 0.12\n",
      "step 32100, training accuracy 0.16\n",
      "step 32200, training accuracy 0.06\n",
      "step 32300, training accuracy 0.22\n",
      "step 32400, training accuracy 0.08\n",
      "step 32500, training accuracy 0.08\n",
      "step 32600, training accuracy 0.12\n",
      "step 32700, training accuracy 0.12\n",
      "step 32800, training accuracy 0.2\n",
      "step 32900, training accuracy 0.08\n",
      "step 33000, training accuracy 0.1\n",
      "step 33100, training accuracy 0.06\n",
      "step 33200, training accuracy 0.08\n",
      "step 33300, training accuracy 0.24\n",
      "step 33400, training accuracy 0.06\n",
      "step 33500, training accuracy 0.12\n",
      "step 33600, training accuracy 0.08\n",
      "step 33700, training accuracy 0.08\n",
      "step 33800, training accuracy 0.1\n",
      "step 33900, training accuracy 0.12\n",
      "step 34000, training accuracy 0.08\n",
      "step 34100, training accuracy 0.12\n",
      "step 34200, training accuracy 0.14\n",
      "step 34300, training accuracy 0.14\n",
      "step 34400, training accuracy 0.2\n",
      "step 34500, training accuracy 0.14\n",
      "step 34600, training accuracy 0.02\n",
      "step 34700, training accuracy 0.16\n",
      "step 34800, training accuracy 0.12\n",
      "step 34900, training accuracy 0.08\n",
      "step 35000, training accuracy 0.08\n",
      "step 35100, training accuracy 0.14\n",
      "step 35200, training accuracy 0.12\n",
      "step 35300, training accuracy 0.12\n",
      "step 35400, training accuracy 0.1\n",
      "step 35500, training accuracy 0.1\n",
      "step 35600, training accuracy 0.1\n",
      "step 35700, training accuracy 0.08\n",
      "step 35800, training accuracy 0.04\n",
      "step 35900, training accuracy 0.16\n",
      "step 36000, training accuracy 0.12\n",
      "step 36100, training accuracy 0.22\n",
      "step 36200, training accuracy 0.1\n",
      "step 36300, training accuracy 0.12\n",
      "step 36400, training accuracy 0.16\n",
      "step 36500, training accuracy 0.08\n",
      "step 36600, training accuracy 0.16\n",
      "step 36700, training accuracy 0.16\n",
      "step 36800, training accuracy 0.08\n",
      "step 36900, training accuracy 0.08\n",
      "step 37000, training accuracy 0.08\n",
      "step 37100, training accuracy 0.14\n",
      "step 37200, training accuracy 0.1\n",
      "step 37300, training accuracy 0.14\n",
      "step 37400, training accuracy 0.12\n",
      "step 37500, training accuracy 0.1\n",
      "step 37600, training accuracy 0.12\n",
      "step 37700, training accuracy 0.12\n",
      "step 37800, training accuracy 0.22\n",
      "step 37900, training accuracy 0.16\n",
      "step 38000, training accuracy 0.08\n",
      "step 38100, training accuracy 0.1\n",
      "step 38200, training accuracy 0.2\n",
      "step 38300, training accuracy 0.16\n",
      "step 38400, training accuracy 0.1\n",
      "step 38500, training accuracy 0.16\n",
      "step 38600, training accuracy 0.08\n",
      "step 38700, training accuracy 0.06\n",
      "step 38800, training accuracy 0.14\n",
      "step 38900, training accuracy 0.12\n",
      "step 39000, training accuracy 0.18\n",
      "step 39100, training accuracy 0.14\n",
      "step 39200, training accuracy 0.12\n",
      "step 39300, training accuracy 0.2\n",
      "step 39400, training accuracy 0.04\n",
      "step 39500, training accuracy 0.02\n",
      "step 39600, training accuracy 0.08\n",
      "step 39700, training accuracy 0.06\n",
      "step 39800, training accuracy 0.1\n",
      "step 39900, training accuracy 0.12\n",
      "step 40000, training accuracy 0.08\n",
      "step 40100, training accuracy 0.14\n",
      "step 40200, training accuracy 0.1\n",
      "step 40300, training accuracy 0.12\n",
      "step 40400, training accuracy 0.18\n",
      "step 40500, training accuracy 0.1\n",
      "step 40600, training accuracy 0.06\n",
      "step 40700, training accuracy 0.1\n",
      "step 40800, training accuracy 0.08\n",
      "step 40900, training accuracy 0.06\n",
      "step 41000, training accuracy 0.18\n",
      "step 41100, training accuracy 0.18\n",
      "step 41200, training accuracy 0.06\n",
      "step 41300, training accuracy 0.12\n",
      "step 41400, training accuracy 0.1\n",
      "step 41500, training accuracy 0.04\n",
      "step 41600, training accuracy 0.14\n",
      "step 41700, training accuracy 0.08\n",
      "step 41800, training accuracy 0.04\n",
      "step 41900, training accuracy 0.08\n",
      "step 42000, training accuracy 0.12\n",
      "step 42100, training accuracy 0.02\n",
      "step 42200, training accuracy 0.14\n",
      "step 42300, training accuracy 0.04\n",
      "step 42400, training accuracy 0.12\n",
      "step 42500, training accuracy 0.14\n",
      "step 42600, training accuracy 0.08\n",
      "step 42700, training accuracy 0.08\n",
      "step 42800, training accuracy 0.14\n",
      "step 42900, training accuracy 0.12\n",
      "step 43000, training accuracy 0.08\n",
      "step 43100, training accuracy 0.1\n",
      "step 43200, training accuracy 0.12\n",
      "step 43300, training accuracy 0.04\n",
      "step 43400, training accuracy 0.06\n",
      "step 43500, training accuracy 0.12\n",
      "step 43600, training accuracy 0.12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fa04d60d9e3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step %d, training accuracy %g\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m#   summary, _, outshape, wc111, bc111, yop, yr, yopv, yc, hp1, hp2 = sess.run([merged_summary_op,train_step,out_shape, W_conv1, b_conv1, y_outer_product, y_raw, y_outer_product_vec, y_conv, h_pool1, h_pool2], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m   \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwc111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged_summary_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_conv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_conv1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_pool1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;31m#   print(\"out shape\", outshape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tuna/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  1.]]\n",
      "\n",
      " [[ 1.  1.]]\n",
      "\n",
      " [[ 1.  1.]]]\n",
      "[[[ 1.]\n",
      "  [ 1.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 1.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 1.]]]\n"
     ]
    }
   ],
   "source": [
    "first = np.ones((3, 1, 2))\n",
    "second = np.ones((3, 2, 1))\n",
    "print(first)\n",
    "print(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.]],\n",
       "\n",
       "       [[ 2.]],\n",
       "\n",
       "       [[ 2.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(first, second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.76\n",
      "step 200, training accuracy 0.92\n",
      "step 300, training accuracy 0.88\n",
      "step 400, training accuracy 0.96\n",
      "step 500, training accuracy 0.94\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.92\n",
      "step 900, training accuracy 0.98\n",
      "step 1000, training accuracy 0.94\n",
      "step 1100, training accuracy 0.94\n",
      "step 1200, training accuracy 0.98\n",
      "step 1300, training accuracy 1\n",
      "step 1400, training accuracy 0.98\n",
      "test accuracy 0.9718\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "image = np.ones((2,10,10,3))\n",
    "image[0,0,0,0] = 13\n",
    "image[0,0,0,2] = 20\n",
    "image[1,0,0,0] = 33\n",
    "image[1,7,0,2] = 44\n",
    "print(image.shape)\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 5, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 13.,   1.,  20.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]]],\n",
       "\n",
       "\n",
       "       [[[ 33.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,  44.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]],\n",
       "\n",
       "        [[  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.],\n",
       "         [  1.,   1.,   1.]]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = max_pool_forward_naive(image)\n",
    "print(output.shape)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_custom_crazy_slow(x, batch_size= 50):\n",
    "  print(x.shape)\n",
    "  N, H, W, C = x.shape\n",
    "  N = batch_size\n",
    "  pool_height, pool_width, stride = 2, 2, 2\n",
    "  assert (H - pool_height) % stride == 0\n",
    "  assert (W - pool_width) % stride == 0\n",
    "\n",
    "\n",
    "  out_height = (H - pool_height) / stride + 1\n",
    "  out_width = (W - pool_width) / stride + 1\n",
    "  \n",
    "  \n",
    "    \n",
    "  output = []\n",
    "\n",
    "#   out = tf.zeros(tf.shape(x))\n",
    "\n",
    "#   out = np.zeros((N, out_height, out_width, C))\n",
    "  #  for each channel\n",
    "  print(\"1\")\n",
    "  for c in xrange(C):\n",
    "      print(c)\n",
    "      #  for each passed image\n",
    "      for n in xrange(N):\n",
    "          print(n)\n",
    "          idx_i = 0\n",
    "            \n",
    "          for i in xrange(pool_height, H+1, stride):\n",
    "              print(i)\n",
    "              idx_j = 0\n",
    "              for j in xrange(pool_width, W+1, stride):\n",
    "                  field = x[n,i-pool_height:i,j-pool_width:j,c]\n",
    "                  output.append(tf.reduce_max(field))\n",
    "#                   out[n,idx_i, idx_j, c] = tf.reduce_max(field)\n",
    "                  idx_j += 1\n",
    "              idx_i += 1\n",
    "            \n",
    "  output = tf.reshape(tf.pack(output), shape=(N, H, W, C))\n",
    "            \n",
    "  return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
